{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxLn3O2coDx-"
   },
   "source": [
    "# Train GPT-2 on OpenWebText w/ Distributionally Robust Optimization\n",
    "\n",
    "See python file of the same name as this notebook for the production version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/kdbanman/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub as hf_hub\n",
    "\n",
    "def read_key(filename):\n",
    "    with open(filename) as f:\n",
    "        key = f.read().strip()\n",
    "    return key\n",
    "\n",
    "hf_hub.login(token=read_key('huggingface.key'), write_permission=True, add_to_git_credential=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dLod8x0YoDyG"
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "tokenized_datasets = load_from_disk('tokenized-openwebtext')\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LcgXjRQtoDyG"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "\n",
    "def dro_loss(inputs, logits, alpha=0.8):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    \n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "\n",
    "    if alpha < 1.0:\n",
    "        # Keep only largest alpha-fraction of losses by reweighting smallest (1-alpha)-fraction to zero\n",
    "        num_samples = len(loss_per_sample)\n",
    "        num_to_ignore = num_samples - int(num_samples * alpha)\n",
    "\n",
    "        if num_to_ignore >= 1 or num_to_ignore < num_samples:\n",
    "            cutoff_value, _cutoff_index = torch.kthvalue(loss_per_sample, num_to_ignore, dim=0)\n",
    "            loss_per_sample[loss_per_sample < cutoff_value] = 0\n",
    "        else:\n",
    "            print(\"ERROR: crazy reweighting request from the following.  Skipping DRO reweighting.\")\n",
    "            priunt(f'alpha: {alpha}')\n",
    "            priunt(f'num_samples: {num_samples}')\n",
    "            priunt(f'num_to_ignore: {num_to_ignore}')\n",
    "            print(f'losses: {loss_per_sample}')\n",
    "    \n",
    "    return loss_per_sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y1FpYVLmoDyG"
   },
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "\n",
    "\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q9iO16NIoDyH"
   },
   "outputs": [],
   "source": [
    "def evaluate(max_eval_batches=None):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    if max_eval_batches is None:\n",
    "        max_eval_batches = len(eval_dataloader)\n",
    "        \n",
    "    for step, batch in tqdm(\n",
    "        enumerate(eval_dataloader), total=max_eval_batches\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "\n",
    "        losses.append(accelerator.gather(outputs.loss))\n",
    "        \n",
    "        if step >= max_eval_batches:\n",
    "            break\n",
    "\n",
    "    if len(losses[0].shape) == 0:\n",
    "        loss = torch.mean(torch.stack(losses))\n",
    "    else:\n",
    "        loss = torch.mean(torch.cat(losses))\n",
    "        \n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rs1R-j2uoDyE"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "# For now, the dataset is tokenized in advance using context_length, so this value is fixed\n",
    "# at tokenization time.  In the future, tokenization should really be streamed.  Then \n",
    "# context_length can be varied.\n",
    "context_length = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EBsh2pt_oDyH"
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IiYTyRRdoDyH"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(get_grouped_params(model), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SH-XmU85oDyH"
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(cpu=False)\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "slO42TVjoDyH"
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IpNFthoOoDyI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kdbanman/gpt2-openwebtext-dro-test'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"gpt2-openwebtext-dro-test\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "try:\n",
    "    huggingface_hub.model_info(repo_name)\n",
    "except huggingface_hub.utils.RepositoryNotFoundError:\n",
    "    huggingface_hub.create_repo(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ej1jel1toDyI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/gpt2-openwebtext-dro-test is already a clone of https://huggingface.co/kdbanman/gpt2-openwebtext-dro-test. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "output_dir = model_name\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gyOLS-JxoDyI"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414702115f04aa68d4541178a8038d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/878614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.0, 0.0], 'samples/contexts': 256, 'samples/tokens': 65536, 'gradient_steps': 0, 'loss/train': 71.26820373535156}\n",
      "{'lr': [5e-07, 5e-07], 'samples/contexts': 512, 'samples/tokens': 131072, 'gradient_steps': 1, 'loss/train': 71.38358306884766}\n",
      "{'lr': [1e-06, 1e-06], 'samples/contexts': 768, 'samples/tokens': 196608, 'gradient_steps': 2, 'loss/train': 71.17308044433594}\n",
      "{'lr': [1.5e-06, 1.5e-06], 'samples/contexts': 1024, 'samples/tokens': 262144, 'gradient_steps': 3, 'loss/train': 70.84748840332031}\n",
      "{'lr': [2e-06, 2e-06], 'samples/contexts': 1280, 'samples/tokens': 327680, 'gradient_steps': 4, 'loss/train': 70.48038482666016}\n",
      "{'lr': [2.5e-06, 2.5e-06], 'samples/contexts': 1536, 'samples/tokens': 393216, 'gradient_steps': 5, 'loss/train': 69.88656616210938}\n",
      "{'lr': [3e-06, 3e-06], 'samples/contexts': 1792, 'samples/tokens': 458752, 'gradient_steps': 6, 'loss/train': 69.14768981933594}\n",
      "{'lr': [3.5e-06, 3.5e-06], 'samples/contexts': 2048, 'samples/tokens': 524288, 'gradient_steps': 7, 'loss/train': 68.67745208740234}\n",
      "{'lr': [4e-06, 4e-06], 'samples/contexts': 2304, 'samples/tokens': 589824, 'gradient_steps': 8, 'loss/train': 67.72896575927734}\n",
      "{'lr': [4.5e-06, 4.5e-06], 'samples/contexts': 2560, 'samples/tokens': 655360, 'gradient_steps': 9, 'loss/train': 67.29814147949219}\n",
      "{'lr': [5e-06, 5e-06], 'samples/contexts': 2816, 'samples/tokens': 720896, 'gradient_steps': 10, 'loss/train': 66.65061950683594}\n",
      "{'lr': [5.5e-06, 5.5e-06], 'samples/contexts': 3072, 'samples/tokens': 786432, 'gradient_steps': 11, 'loss/train': 65.77337646484375}\n",
      "{'lr': [6e-06, 6e-06], 'samples/contexts': 3328, 'samples/tokens': 851968, 'gradient_steps': 12, 'loss/train': 65.67396545410156}\n",
      "{'lr': [6.5e-06, 6.5e-06], 'samples/contexts': 3584, 'samples/tokens': 917504, 'gradient_steps': 13, 'loss/train': 65.27703857421875}\n",
      "{'lr': [7e-06, 7e-06], 'samples/contexts': 3840, 'samples/tokens': 983040, 'gradient_steps': 14, 'loss/train': 64.61417388916016}\n",
      "{'lr': [7.5e-06, 7.5e-06], 'samples/contexts': 4096, 'samples/tokens': 1048576, 'gradient_steps': 15, 'loss/train': 64.42716217041016}\n",
      "{'lr': [8e-06, 8e-06], 'samples/contexts': 4352, 'samples/tokens': 1114112, 'gradient_steps': 16, 'loss/train': 64.20747375488281}\n",
      "{'lr': [8.500000000000002e-06, 8.500000000000002e-06], 'samples/contexts': 4608, 'samples/tokens': 1179648, 'gradient_steps': 17, 'loss/train': 63.89588165283203}\n",
      "{'lr': [9e-06, 9e-06], 'samples/contexts': 4864, 'samples/tokens': 1245184, 'gradient_steps': 18, 'loss/train': 63.911991119384766}\n",
      "{'lr': [9.5e-06, 9.5e-06], 'samples/contexts': 5120, 'samples/tokens': 1310720, 'gradient_steps': 19, 'loss/train': 63.68238067626953}\n",
      "{'lr': [1e-05, 1e-05], 'samples/contexts': 5376, 'samples/tokens': 1376256, 'gradient_steps': 20, 'loss/train': 63.609535217285156}\n",
      "{'lr': [1.0500000000000001e-05, 1.0500000000000001e-05], 'samples/contexts': 5632, 'samples/tokens': 1441792, 'gradient_steps': 21, 'loss/train': 62.88486862182617}\n",
      "{'lr': [1.1e-05, 1.1e-05], 'samples/contexts': 5888, 'samples/tokens': 1507328, 'gradient_steps': 22, 'loss/train': 62.6545295715332}\n",
      "{'lr': [1.15e-05, 1.15e-05], 'samples/contexts': 6144, 'samples/tokens': 1572864, 'gradient_steps': 23, 'loss/train': 62.54303741455078}\n",
      "{'lr': [1.2e-05, 1.2e-05], 'samples/contexts': 6400, 'samples/tokens': 1638400, 'gradient_steps': 24, 'loss/train': 62.42842102050781}\n",
      "{'lr': [1.25e-05, 1.25e-05], 'samples/contexts': 6656, 'samples/tokens': 1703936, 'gradient_steps': 25, 'loss/train': 62.380531311035156}\n",
      "{'lr': [1.3e-05, 1.3e-05], 'samples/contexts': 6912, 'samples/tokens': 1769472, 'gradient_steps': 26, 'loss/train': 61.907649993896484}\n",
      "{'lr': [1.35e-05, 1.35e-05], 'samples/contexts': 7168, 'samples/tokens': 1835008, 'gradient_steps': 27, 'loss/train': 61.972007751464844}\n",
      "{'lr': [1.4e-05, 1.4e-05], 'samples/contexts': 7424, 'samples/tokens': 1900544, 'gradient_steps': 28, 'loss/train': 61.164649963378906}\n",
      "{'lr': [1.4500000000000002e-05, 1.4500000000000002e-05], 'samples/contexts': 7680, 'samples/tokens': 1966080, 'gradient_steps': 29, 'loss/train': 61.37248992919922}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e61d5b51f4949e5a380608f798d5d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 9.393847465515137, 'perplexity': 12014.2353515625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [1.5e-05, 1.5e-05], 'samples/contexts': 7936, 'samples/tokens': 2031616, 'gradient_steps': 30, 'loss/train': 61.213165283203125}\n",
      "{'lr': [1.55e-05, 1.55e-05], 'samples/contexts': 8192, 'samples/tokens': 2097152, 'gradient_steps': 31, 'loss/train': 61.22166061401367}\n",
      "{'lr': [1.6e-05, 1.6e-05], 'samples/contexts': 8448, 'samples/tokens': 2162688, 'gradient_steps': 32, 'loss/train': 61.35581588745117}\n",
      "{'lr': [1.65e-05, 1.65e-05], 'samples/contexts': 8704, 'samples/tokens': 2228224, 'gradient_steps': 33, 'loss/train': 61.499610900878906}\n",
      "{'lr': [1.7000000000000003e-05, 1.7000000000000003e-05], 'samples/contexts': 8960, 'samples/tokens': 2293760, 'gradient_steps': 34, 'loss/train': 61.47796630859375}\n",
      "{'lr': [1.7500000000000002e-05, 1.7500000000000002e-05], 'samples/contexts': 9216, 'samples/tokens': 2359296, 'gradient_steps': 35, 'loss/train': 60.99376678466797}\n",
      "{'lr': [1.8e-05, 1.8e-05], 'samples/contexts': 9472, 'samples/tokens': 2424832, 'gradient_steps': 36, 'loss/train': 60.407493591308594}\n",
      "{'lr': [1.85e-05, 1.85e-05], 'samples/contexts': 9728, 'samples/tokens': 2490368, 'gradient_steps': 37, 'loss/train': 60.767059326171875}\n",
      "{'lr': [1.9e-05, 1.9e-05], 'samples/contexts': 9984, 'samples/tokens': 2555904, 'gradient_steps': 38, 'loss/train': 59.775733947753906}\n",
      "{'lr': [1.95e-05, 1.95e-05], 'samples/contexts': 10240, 'samples/tokens': 2621440, 'gradient_steps': 39, 'loss/train': 60.62042236328125}\n",
      "{'lr': [2e-05, 2e-05], 'samples/contexts': 10496, 'samples/tokens': 2686976, 'gradient_steps': 40, 'loss/train': 59.959190368652344}\n",
      "{'lr': [2.05e-05, 2.05e-05], 'samples/contexts': 10752, 'samples/tokens': 2752512, 'gradient_steps': 41, 'loss/train': 60.21485137939453}\n",
      "{'lr': [2.1000000000000002e-05, 2.1000000000000002e-05], 'samples/contexts': 11008, 'samples/tokens': 2818048, 'gradient_steps': 42, 'loss/train': 59.70905303955078}\n",
      "{'lr': [2.1499999999999997e-05, 2.1499999999999997e-05], 'samples/contexts': 11264, 'samples/tokens': 2883584, 'gradient_steps': 43, 'loss/train': 59.487247467041016}\n",
      "{'lr': [2.2e-05, 2.2e-05], 'samples/contexts': 11520, 'samples/tokens': 2949120, 'gradient_steps': 44, 'loss/train': 58.63663101196289}\n",
      "{'lr': [2.2499999999999998e-05, 2.2499999999999998e-05], 'samples/contexts': 11776, 'samples/tokens': 3014656, 'gradient_steps': 45, 'loss/train': 59.02186965942383}\n",
      "{'lr': [2.3e-05, 2.3e-05], 'samples/contexts': 12032, 'samples/tokens': 3080192, 'gradient_steps': 46, 'loss/train': 59.28575134277344}\n",
      "{'lr': [2.3500000000000002e-05, 2.3500000000000002e-05], 'samples/contexts': 12288, 'samples/tokens': 3145728, 'gradient_steps': 47, 'loss/train': 58.60862350463867}\n",
      "{'lr': [2.4e-05, 2.4e-05], 'samples/contexts': 12544, 'samples/tokens': 3211264, 'gradient_steps': 48, 'loss/train': 58.07691955566406}\n",
      "{'lr': [2.4500000000000003e-05, 2.4500000000000003e-05], 'samples/contexts': 12800, 'samples/tokens': 3276800, 'gradient_steps': 49, 'loss/train': 57.25971221923828}\n",
      "{'lr': [2.5e-05, 2.5e-05], 'samples/contexts': 13056, 'samples/tokens': 3342336, 'gradient_steps': 50, 'loss/train': 57.624656677246094}\n",
      "{'lr': [2.55e-05, 2.55e-05], 'samples/contexts': 13312, 'samples/tokens': 3407872, 'gradient_steps': 51, 'loss/train': 57.551422119140625}\n",
      "{'lr': [2.6e-05, 2.6e-05], 'samples/contexts': 13568, 'samples/tokens': 3473408, 'gradient_steps': 52, 'loss/train': 57.9296989440918}\n",
      "{'lr': [2.65e-05, 2.65e-05], 'samples/contexts': 13824, 'samples/tokens': 3538944, 'gradient_steps': 53, 'loss/train': 57.751651763916016}\n",
      "{'lr': [2.7e-05, 2.7e-05], 'samples/contexts': 14080, 'samples/tokens': 3604480, 'gradient_steps': 54, 'loss/train': 57.54769515991211}\n",
      "{'lr': [2.75e-05, 2.75e-05], 'samples/contexts': 14336, 'samples/tokens': 3670016, 'gradient_steps': 55, 'loss/train': 57.49616241455078}\n",
      "{'lr': [2.8e-05, 2.8e-05], 'samples/contexts': 14592, 'samples/tokens': 3735552, 'gradient_steps': 56, 'loss/train': 56.262062072753906}\n",
      "{'lr': [2.85e-05, 2.85e-05], 'samples/contexts': 14848, 'samples/tokens': 3801088, 'gradient_steps': 57, 'loss/train': 57.35528564453125}\n",
      "{'lr': [2.9000000000000004e-05, 2.9000000000000004e-05], 'samples/contexts': 15104, 'samples/tokens': 3866624, 'gradient_steps': 58, 'loss/train': 56.31556701660156}\n",
      "{'lr': [2.95e-05, 2.95e-05], 'samples/contexts': 15360, 'samples/tokens': 3932160, 'gradient_steps': 59, 'loss/train': 55.94434356689453}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d969a75c5814697b1439acec8c3bb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 8.549030303955078, 'perplexity': 5161.74658203125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [3e-05, 3e-05], 'samples/contexts': 15616, 'samples/tokens': 3997696, 'gradient_steps': 60, 'loss/train': 55.753021240234375}\n",
      "{'lr': [3.05e-05, 3.05e-05], 'samples/contexts': 15872, 'samples/tokens': 4063232, 'gradient_steps': 61, 'loss/train': 55.97893524169922}\n",
      "{'lr': [3.1e-05, 3.1e-05], 'samples/contexts': 16128, 'samples/tokens': 4128768, 'gradient_steps': 62, 'loss/train': 55.91229248046875}\n",
      "{'lr': [3.15e-05, 3.15e-05], 'samples/contexts': 16384, 'samples/tokens': 4194304, 'gradient_steps': 63, 'loss/train': 55.927772521972656}\n",
      "{'lr': [3.2e-05, 3.2e-05], 'samples/contexts': 16640, 'samples/tokens': 4259840, 'gradient_steps': 64, 'loss/train': 55.96785354614258}\n",
      "{'lr': [3.2500000000000004e-05, 3.2500000000000004e-05], 'samples/contexts': 16896, 'samples/tokens': 4325376, 'gradient_steps': 65, 'loss/train': 54.23414993286133}\n",
      "{'lr': [3.3e-05, 3.3e-05], 'samples/contexts': 17152, 'samples/tokens': 4390912, 'gradient_steps': 66, 'loss/train': 54.26689147949219}\n",
      "{'lr': [3.35e-05, 3.35e-05], 'samples/contexts': 17408, 'samples/tokens': 4456448, 'gradient_steps': 67, 'loss/train': 55.09267807006836}\n",
      "{'lr': [3.4000000000000007e-05, 3.4000000000000007e-05], 'samples/contexts': 17664, 'samples/tokens': 4521984, 'gradient_steps': 68, 'loss/train': 55.02534484863281}\n",
      "{'lr': [3.4500000000000005e-05, 3.4500000000000005e-05], 'samples/contexts': 17920, 'samples/tokens': 4587520, 'gradient_steps': 69, 'loss/train': 54.44683837890625}\n",
      "{'lr': [3.5000000000000004e-05, 3.5000000000000004e-05], 'samples/contexts': 18176, 'samples/tokens': 4653056, 'gradient_steps': 70, 'loss/train': 53.685001373291016}\n",
      "{'lr': [3.5499999999999996e-05, 3.5499999999999996e-05], 'samples/contexts': 18432, 'samples/tokens': 4718592, 'gradient_steps': 71, 'loss/train': 54.14072036743164}\n",
      "{'lr': [3.6e-05, 3.6e-05], 'samples/contexts': 18688, 'samples/tokens': 4784128, 'gradient_steps': 72, 'loss/train': 53.784976959228516}\n",
      "{'lr': [3.65e-05, 3.65e-05], 'samples/contexts': 18944, 'samples/tokens': 4849664, 'gradient_steps': 73, 'loss/train': 53.7667236328125}\n",
      "{'lr': [3.7e-05, 3.7e-05], 'samples/contexts': 19200, 'samples/tokens': 4915200, 'gradient_steps': 74, 'loss/train': 54.29448318481445}\n",
      "{'lr': [3.75e-05, 3.75e-05], 'samples/contexts': 19456, 'samples/tokens': 4980736, 'gradient_steps': 75, 'loss/train': 53.38847351074219}\n",
      "{'lr': [3.8e-05, 3.8e-05], 'samples/contexts': 19712, 'samples/tokens': 5046272, 'gradient_steps': 76, 'loss/train': 52.57571792602539}\n",
      "{'lr': [3.85e-05, 3.85e-05], 'samples/contexts': 19968, 'samples/tokens': 5111808, 'gradient_steps': 77, 'loss/train': 54.016151428222656}\n",
      "{'lr': [3.9e-05, 3.9e-05], 'samples/contexts': 20224, 'samples/tokens': 5177344, 'gradient_steps': 78, 'loss/train': 53.876869201660156}\n",
      "{'lr': [3.95e-05, 3.95e-05], 'samples/contexts': 20480, 'samples/tokens': 5242880, 'gradient_steps': 79, 'loss/train': 51.66902160644531}\n",
      "{'lr': [4e-05, 4e-05], 'samples/contexts': 20736, 'samples/tokens': 5308416, 'gradient_steps': 80, 'loss/train': 52.62601852416992}\n",
      "{'lr': [4.05e-05, 4.05e-05], 'samples/contexts': 20992, 'samples/tokens': 5373952, 'gradient_steps': 81, 'loss/train': 52.01272201538086}\n",
      "{'lr': [4.1e-05, 4.1e-05], 'samples/contexts': 21248, 'samples/tokens': 5439488, 'gradient_steps': 82, 'loss/train': 52.464088439941406}\n",
      "{'lr': [4.1500000000000006e-05, 4.1500000000000006e-05], 'samples/contexts': 21504, 'samples/tokens': 5505024, 'gradient_steps': 83, 'loss/train': 52.253211975097656}\n",
      "{'lr': [4.2000000000000004e-05, 4.2000000000000004e-05], 'samples/contexts': 21760, 'samples/tokens': 5570560, 'gradient_steps': 84, 'loss/train': 50.91507339477539}\n",
      "{'lr': [4.25e-05, 4.25e-05], 'samples/contexts': 22016, 'samples/tokens': 5636096, 'gradient_steps': 85, 'loss/train': 51.33777618408203}\n",
      "{'lr': [4.2999999999999995e-05, 4.2999999999999995e-05], 'samples/contexts': 22272, 'samples/tokens': 5701632, 'gradient_steps': 86, 'loss/train': 51.980064392089844}\n",
      "{'lr': [4.35e-05, 4.35e-05], 'samples/contexts': 22528, 'samples/tokens': 5767168, 'gradient_steps': 87, 'loss/train': 51.56831359863281}\n",
      "{'lr': [4.4e-05, 4.4e-05], 'samples/contexts': 22784, 'samples/tokens': 5832704, 'gradient_steps': 88, 'loss/train': 50.129478454589844}\n",
      "{'lr': [4.45e-05, 4.45e-05], 'samples/contexts': 23040, 'samples/tokens': 5898240, 'gradient_steps': 89, 'loss/train': 50.41588592529297}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c93ab24038940e0b95ecd1a46919cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 7.727158069610596, 'perplexity': 2269.144287109375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [4.4999999999999996e-05, 4.4999999999999996e-05], 'samples/contexts': 23296, 'samples/tokens': 5963776, 'gradient_steps': 90, 'loss/train': 49.69676208496094}\n",
      "{'lr': [4.55e-05, 4.55e-05], 'samples/contexts': 23552, 'samples/tokens': 6029312, 'gradient_steps': 91, 'loss/train': 50.529052734375}\n",
      "{'lr': [4.6e-05, 4.6e-05], 'samples/contexts': 23808, 'samples/tokens': 6094848, 'gradient_steps': 92, 'loss/train': 50.180179595947266}\n",
      "{'lr': [4.65e-05, 4.65e-05], 'samples/contexts': 24064, 'samples/tokens': 6160384, 'gradient_steps': 93, 'loss/train': 50.291297912597656}\n",
      "{'lr': [4.7000000000000004e-05, 4.7000000000000004e-05], 'samples/contexts': 24320, 'samples/tokens': 6225920, 'gradient_steps': 94, 'loss/train': 49.10736846923828}\n",
      "{'lr': [4.75e-05, 4.75e-05], 'samples/contexts': 24576, 'samples/tokens': 6291456, 'gradient_steps': 95, 'loss/train': 50.06428527832031}\n",
      "{'lr': [4.8e-05, 4.8e-05], 'samples/contexts': 24832, 'samples/tokens': 6356992, 'gradient_steps': 96, 'loss/train': 49.92585754394531}\n",
      "{'lr': [4.85e-05, 4.85e-05], 'samples/contexts': 25088, 'samples/tokens': 6422528, 'gradient_steps': 97, 'loss/train': 50.53355026245117}\n",
      "{'lr': [4.9000000000000005e-05, 4.9000000000000005e-05], 'samples/contexts': 25344, 'samples/tokens': 6488064, 'gradient_steps': 98, 'loss/train': 49.321678161621094}\n",
      "{'lr': [4.9500000000000004e-05, 4.9500000000000004e-05], 'samples/contexts': 25600, 'samples/tokens': 6553600, 'gradient_steps': 99, 'loss/train': 48.56231689453125}\n",
      "{'lr': [5e-05, 5e-05], 'samples/contexts': 25856, 'samples/tokens': 6619136, 'gradient_steps': 100, 'loss/train': 48.962249755859375}\n",
      "{'lr': [5.05e-05, 5.05e-05], 'samples/contexts': 26112, 'samples/tokens': 6684672, 'gradient_steps': 101, 'loss/train': 50.151527404785156}\n",
      "{'lr': [5.1e-05, 5.1e-05], 'samples/contexts': 26368, 'samples/tokens': 6750208, 'gradient_steps': 102, 'loss/train': 47.96828079223633}\n",
      "{'lr': [5.15e-05, 5.15e-05], 'samples/contexts': 26624, 'samples/tokens': 6815744, 'gradient_steps': 103, 'loss/train': 49.594520568847656}\n",
      "{'lr': [5.2e-05, 5.2e-05], 'samples/contexts': 26880, 'samples/tokens': 6881280, 'gradient_steps': 104, 'loss/train': 48.42619323730469}\n",
      "{'lr': [5.25e-05, 5.25e-05], 'samples/contexts': 27136, 'samples/tokens': 6946816, 'gradient_steps': 105, 'loss/train': 48.462158203125}\n",
      "{'lr': [5.3e-05, 5.3e-05], 'samples/contexts': 27392, 'samples/tokens': 7012352, 'gradient_steps': 106, 'loss/train': 48.98366928100586}\n",
      "{'lr': [5.35e-05, 5.35e-05], 'samples/contexts': 27648, 'samples/tokens': 7077888, 'gradient_steps': 107, 'loss/train': 47.214717864990234}\n",
      "{'lr': [5.4e-05, 5.4e-05], 'samples/contexts': 27904, 'samples/tokens': 7143424, 'gradient_steps': 108, 'loss/train': 48.15377426147461}\n",
      "{'lr': [5.45e-05, 5.45e-05], 'samples/contexts': 28160, 'samples/tokens': 7208960, 'gradient_steps': 109, 'loss/train': 48.78886795043945}\n",
      "{'lr': [5.5e-05, 5.5e-05], 'samples/contexts': 28416, 'samples/tokens': 7274496, 'gradient_steps': 110, 'loss/train': 48.50202178955078}\n",
      "{'lr': [5.55e-05, 5.55e-05], 'samples/contexts': 28672, 'samples/tokens': 7340032, 'gradient_steps': 111, 'loss/train': 49.34773254394531}\n",
      "{'lr': [5.6e-05, 5.6e-05], 'samples/contexts': 28928, 'samples/tokens': 7405568, 'gradient_steps': 112, 'loss/train': 47.62062454223633}\n",
      "{'lr': [5.6500000000000005e-05, 5.6500000000000005e-05], 'samples/contexts': 29184, 'samples/tokens': 7471104, 'gradient_steps': 113, 'loss/train': 46.791717529296875}\n",
      "{'lr': [5.7e-05, 5.7e-05], 'samples/contexts': 29440, 'samples/tokens': 7536640, 'gradient_steps': 114, 'loss/train': 47.53166961669922}\n",
      "{'lr': [5.75e-05, 5.75e-05], 'samples/contexts': 29696, 'samples/tokens': 7602176, 'gradient_steps': 115, 'loss/train': 48.58086395263672}\n",
      "{'lr': [5.800000000000001e-05, 5.800000000000001e-05], 'samples/contexts': 29952, 'samples/tokens': 7667712, 'gradient_steps': 116, 'loss/train': 46.59596252441406}\n",
      "{'lr': [5.8500000000000006e-05, 5.8500000000000006e-05], 'samples/contexts': 30208, 'samples/tokens': 7733248, 'gradient_steps': 117, 'loss/train': 47.504356384277344}\n",
      "{'lr': [5.9e-05, 5.9e-05], 'samples/contexts': 30464, 'samples/tokens': 7798784, 'gradient_steps': 118, 'loss/train': 48.71772003173828}\n",
      "{'lr': [5.9499999999999996e-05, 5.9499999999999996e-05], 'samples/contexts': 30720, 'samples/tokens': 7864320, 'gradient_steps': 119, 'loss/train': 48.12104797363281}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc4f8b076848cf972a2ac7ddf247ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 7.161857604980469, 'perplexity': 1289.3037109375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [6e-05, 6e-05], 'samples/contexts': 30976, 'samples/tokens': 7929856, 'gradient_steps': 120, 'loss/train': 47.732521057128906}\n",
      "{'lr': [6.05e-05, 6.05e-05], 'samples/contexts': 31232, 'samples/tokens': 7995392, 'gradient_steps': 121, 'loss/train': 48.0483512878418}\n",
      "{'lr': [6.1e-05, 6.1e-05], 'samples/contexts': 31488, 'samples/tokens': 8060928, 'gradient_steps': 122, 'loss/train': 46.980018615722656}\n",
      "{'lr': [6.15e-05, 6.15e-05], 'samples/contexts': 31744, 'samples/tokens': 8126464, 'gradient_steps': 123, 'loss/train': 47.76753234863281}\n",
      "{'lr': [6.2e-05, 6.2e-05], 'samples/contexts': 32000, 'samples/tokens': 8192000, 'gradient_steps': 124, 'loss/train': 47.18766784667969}\n",
      "{'lr': [6.25e-05, 6.25e-05], 'samples/contexts': 32256, 'samples/tokens': 8257536, 'gradient_steps': 125, 'loss/train': 46.76532745361328}\n",
      "{'lr': [6.3e-05, 6.3e-05], 'samples/contexts': 32512, 'samples/tokens': 8323072, 'gradient_steps': 126, 'loss/train': 47.926002502441406}\n",
      "{'lr': [6.35e-05, 6.35e-05], 'samples/contexts': 32768, 'samples/tokens': 8388608, 'gradient_steps': 127, 'loss/train': 46.64747619628906}\n",
      "{'lr': [6.4e-05, 6.4e-05], 'samples/contexts': 33024, 'samples/tokens': 8454144, 'gradient_steps': 128, 'loss/train': 46.829837799072266}\n",
      "{'lr': [6.450000000000001e-05, 6.450000000000001e-05], 'samples/contexts': 33280, 'samples/tokens': 8519680, 'gradient_steps': 129, 'loss/train': 47.07405090332031}\n",
      "{'lr': [6.500000000000001e-05, 6.500000000000001e-05], 'samples/contexts': 33536, 'samples/tokens': 8585216, 'gradient_steps': 130, 'loss/train': 46.29621124267578}\n",
      "{'lr': [6.55e-05, 6.55e-05], 'samples/contexts': 33792, 'samples/tokens': 8650752, 'gradient_steps': 131, 'loss/train': 46.928287506103516}\n",
      "{'lr': [6.6e-05, 6.6e-05], 'samples/contexts': 34048, 'samples/tokens': 8716288, 'gradient_steps': 132, 'loss/train': 46.50169372558594}\n",
      "{'lr': [6.65e-05, 6.65e-05], 'samples/contexts': 34304, 'samples/tokens': 8781824, 'gradient_steps': 133, 'loss/train': 45.416831970214844}\n",
      "{'lr': [6.7e-05, 6.7e-05], 'samples/contexts': 34560, 'samples/tokens': 8847360, 'gradient_steps': 134, 'loss/train': 47.53297805786133}\n",
      "{'lr': [6.75e-05, 6.75e-05], 'samples/contexts': 34816, 'samples/tokens': 8912896, 'gradient_steps': 135, 'loss/train': 46.226539611816406}\n",
      "{'lr': [6.800000000000001e-05, 6.800000000000001e-05], 'samples/contexts': 35072, 'samples/tokens': 8978432, 'gradient_steps': 136, 'loss/train': 45.979331970214844}\n",
      "{'lr': [6.850000000000001e-05, 6.850000000000001e-05], 'samples/contexts': 35328, 'samples/tokens': 9043968, 'gradient_steps': 137, 'loss/train': 45.71668243408203}\n",
      "{'lr': [6.900000000000001e-05, 6.900000000000001e-05], 'samples/contexts': 35584, 'samples/tokens': 9109504, 'gradient_steps': 138, 'loss/train': 45.67377471923828}\n",
      "{'lr': [6.950000000000001e-05, 6.950000000000001e-05], 'samples/contexts': 35840, 'samples/tokens': 9175040, 'gradient_steps': 139, 'loss/train': 46.175086975097656}\n",
      "{'lr': [7.000000000000001e-05, 7.000000000000001e-05], 'samples/contexts': 36096, 'samples/tokens': 9240576, 'gradient_steps': 140, 'loss/train': 47.33598327636719}\n",
      "{'lr': [7.049999999999999e-05, 7.049999999999999e-05], 'samples/contexts': 36352, 'samples/tokens': 9306112, 'gradient_steps': 141, 'loss/train': 45.97503662109375}\n",
      "{'lr': [7.099999999999999e-05, 7.099999999999999e-05], 'samples/contexts': 36608, 'samples/tokens': 9371648, 'gradient_steps': 142, 'loss/train': 45.61176300048828}\n",
      "{'lr': [7.149999999999999e-05, 7.149999999999999e-05], 'samples/contexts': 36864, 'samples/tokens': 9437184, 'gradient_steps': 143, 'loss/train': 44.861122131347656}\n",
      "{'lr': [7.2e-05, 7.2e-05], 'samples/contexts': 37120, 'samples/tokens': 9502720, 'gradient_steps': 144, 'loss/train': 45.1405143737793}\n",
      "{'lr': [7.25e-05, 7.25e-05], 'samples/contexts': 37376, 'samples/tokens': 9568256, 'gradient_steps': 145, 'loss/train': 44.48114013671875}\n",
      "{'lr': [7.3e-05, 7.3e-05], 'samples/contexts': 37632, 'samples/tokens': 9633792, 'gradient_steps': 146, 'loss/train': 45.321693420410156}\n",
      "{'lr': [7.35e-05, 7.35e-05], 'samples/contexts': 37888, 'samples/tokens': 9699328, 'gradient_steps': 147, 'loss/train': 44.723026275634766}\n",
      "{'lr': [7.4e-05, 7.4e-05], 'samples/contexts': 38144, 'samples/tokens': 9764864, 'gradient_steps': 148, 'loss/train': 45.87543487548828}\n",
      "{'lr': [7.45e-05, 7.45e-05], 'samples/contexts': 38400, 'samples/tokens': 9830400, 'gradient_steps': 149, 'loss/train': 43.97555160522461}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e91dbefc7342e4a9f7b125bec89482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.897471904754639, 'perplexity': 989.7693481445312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [7.5e-05, 7.5e-05], 'samples/contexts': 38656, 'samples/tokens': 9895936, 'gradient_steps': 150, 'loss/train': 44.45376205444336}\n",
      "{'lr': [7.55e-05, 7.55e-05], 'samples/contexts': 38912, 'samples/tokens': 9961472, 'gradient_steps': 151, 'loss/train': 44.903011322021484}\n",
      "{'lr': [7.6e-05, 7.6e-05], 'samples/contexts': 39168, 'samples/tokens': 10027008, 'gradient_steps': 152, 'loss/train': 46.237728118896484}\n",
      "{'lr': [7.65e-05, 7.65e-05], 'samples/contexts': 39424, 'samples/tokens': 10092544, 'gradient_steps': 153, 'loss/train': 45.43748474121094}\n",
      "{'lr': [7.7e-05, 7.7e-05], 'samples/contexts': 39680, 'samples/tokens': 10158080, 'gradient_steps': 154, 'loss/train': 45.20257568359375}\n",
      "{'lr': [7.75e-05, 7.75e-05], 'samples/contexts': 39936, 'samples/tokens': 10223616, 'gradient_steps': 155, 'loss/train': 45.0079231262207}\n",
      "{'lr': [7.8e-05, 7.8e-05], 'samples/contexts': 40192, 'samples/tokens': 10289152, 'gradient_steps': 156, 'loss/train': 43.668128967285156}\n",
      "{'lr': [7.85e-05, 7.85e-05], 'samples/contexts': 40448, 'samples/tokens': 10354688, 'gradient_steps': 157, 'loss/train': 45.894798278808594}\n",
      "{'lr': [7.9e-05, 7.9e-05], 'samples/contexts': 40704, 'samples/tokens': 10420224, 'gradient_steps': 158, 'loss/train': 43.872520446777344}\n",
      "{'lr': [7.950000000000001e-05, 7.950000000000001e-05], 'samples/contexts': 40960, 'samples/tokens': 10485760, 'gradient_steps': 159, 'loss/train': 45.30121994018555}\n",
      "{'lr': [8e-05, 8e-05], 'samples/contexts': 41216, 'samples/tokens': 10551296, 'gradient_steps': 160, 'loss/train': 45.605567932128906}\n",
      "{'lr': [8.05e-05, 8.05e-05], 'samples/contexts': 41472, 'samples/tokens': 10616832, 'gradient_steps': 161, 'loss/train': 44.81232452392578}\n",
      "{'lr': [8.1e-05, 8.1e-05], 'samples/contexts': 41728, 'samples/tokens': 10682368, 'gradient_steps': 162, 'loss/train': 45.72864532470703}\n",
      "{'lr': [8.15e-05, 8.15e-05], 'samples/contexts': 41984, 'samples/tokens': 10747904, 'gradient_steps': 163, 'loss/train': 44.977325439453125}\n",
      "{'lr': [8.2e-05, 8.2e-05], 'samples/contexts': 42240, 'samples/tokens': 10813440, 'gradient_steps': 164, 'loss/train': 44.127586364746094}\n",
      "{'lr': [8.25e-05, 8.25e-05], 'samples/contexts': 42496, 'samples/tokens': 10878976, 'gradient_steps': 165, 'loss/train': 43.81761932373047}\n",
      "{'lr': [8.300000000000001e-05, 8.300000000000001e-05], 'samples/contexts': 42752, 'samples/tokens': 10944512, 'gradient_steps': 166, 'loss/train': 45.63435745239258}\n",
      "{'lr': [8.350000000000001e-05, 8.350000000000001e-05], 'samples/contexts': 43008, 'samples/tokens': 11010048, 'gradient_steps': 167, 'loss/train': 46.07978057861328}\n",
      "{'lr': [8.400000000000001e-05, 8.400000000000001e-05], 'samples/contexts': 43264, 'samples/tokens': 11075584, 'gradient_steps': 168, 'loss/train': 44.608341217041016}\n",
      "{'lr': [8.450000000000001e-05, 8.450000000000001e-05], 'samples/contexts': 43520, 'samples/tokens': 11141120, 'gradient_steps': 169, 'loss/train': 44.00666809082031}\n",
      "{'lr': [8.5e-05, 8.5e-05], 'samples/contexts': 43776, 'samples/tokens': 11206656, 'gradient_steps': 170, 'loss/train': 44.54306411743164}\n",
      "{'lr': [8.55e-05, 8.55e-05], 'samples/contexts': 44032, 'samples/tokens': 11272192, 'gradient_steps': 171, 'loss/train': 44.66932678222656}\n",
      "{'lr': [8.599999999999999e-05, 8.599999999999999e-05], 'samples/contexts': 44288, 'samples/tokens': 11337728, 'gradient_steps': 172, 'loss/train': 43.676177978515625}\n",
      "{'lr': [8.65e-05, 8.65e-05], 'samples/contexts': 44544, 'samples/tokens': 11403264, 'gradient_steps': 173, 'loss/train': 44.5018196105957}\n",
      "{'lr': [8.7e-05, 8.7e-05], 'samples/contexts': 44800, 'samples/tokens': 11468800, 'gradient_steps': 174, 'loss/train': 44.33465576171875}\n",
      "{'lr': [8.75e-05, 8.75e-05], 'samples/contexts': 45056, 'samples/tokens': 11534336, 'gradient_steps': 175, 'loss/train': 44.74004364013672}\n",
      "{'lr': [8.8e-05, 8.8e-05], 'samples/contexts': 45312, 'samples/tokens': 11599872, 'gradient_steps': 176, 'loss/train': 45.04154968261719}\n",
      "{'lr': [8.85e-05, 8.85e-05], 'samples/contexts': 45568, 'samples/tokens': 11665408, 'gradient_steps': 177, 'loss/train': 44.929595947265625}\n",
      "{'lr': [8.9e-05, 8.9e-05], 'samples/contexts': 45824, 'samples/tokens': 11730944, 'gradient_steps': 178, 'loss/train': 44.066864013671875}\n",
      "{'lr': [8.95e-05, 8.95e-05], 'samples/contexts': 46080, 'samples/tokens': 11796480, 'gradient_steps': 179, 'loss/train': 44.767372131347656}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622c4097511645b1adafb30515642fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.719207763671875, 'perplexity': 828.1611328125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [8.999999999999999e-05, 8.999999999999999e-05], 'samples/contexts': 46336, 'samples/tokens': 11862016, 'gradient_steps': 180, 'loss/train': 44.53252029418945}\n",
      "{'lr': [9.05e-05, 9.05e-05], 'samples/contexts': 46592, 'samples/tokens': 11927552, 'gradient_steps': 181, 'loss/train': 44.493221282958984}\n",
      "{'lr': [9.1e-05, 9.1e-05], 'samples/contexts': 46848, 'samples/tokens': 11993088, 'gradient_steps': 182, 'loss/train': 44.08295440673828}\n",
      "{'lr': [9.15e-05, 9.15e-05], 'samples/contexts': 47104, 'samples/tokens': 12058624, 'gradient_steps': 183, 'loss/train': 43.55826187133789}\n",
      "{'lr': [9.2e-05, 9.2e-05], 'samples/contexts': 47360, 'samples/tokens': 12124160, 'gradient_steps': 184, 'loss/train': 44.5527229309082}\n",
      "{'lr': [9.25e-05, 9.25e-05], 'samples/contexts': 47616, 'samples/tokens': 12189696, 'gradient_steps': 185, 'loss/train': 44.33708953857422}\n",
      "{'lr': [9.3e-05, 9.3e-05], 'samples/contexts': 47872, 'samples/tokens': 12255232, 'gradient_steps': 186, 'loss/train': 43.898189544677734}\n",
      "{'lr': [9.35e-05, 9.35e-05], 'samples/contexts': 48128, 'samples/tokens': 12320768, 'gradient_steps': 187, 'loss/train': 43.270423889160156}\n",
      "{'lr': [9.400000000000001e-05, 9.400000000000001e-05], 'samples/contexts': 48384, 'samples/tokens': 12386304, 'gradient_steps': 188, 'loss/train': 43.72720718383789}\n",
      "{'lr': [9.45e-05, 9.45e-05], 'samples/contexts': 48640, 'samples/tokens': 12451840, 'gradient_steps': 189, 'loss/train': 43.98456954956055}\n",
      "{'lr': [9.5e-05, 9.5e-05], 'samples/contexts': 48896, 'samples/tokens': 12517376, 'gradient_steps': 190, 'loss/train': 43.650367736816406}\n",
      "{'lr': [9.55e-05, 9.55e-05], 'samples/contexts': 49152, 'samples/tokens': 12582912, 'gradient_steps': 191, 'loss/train': 43.45905303955078}\n",
      "{'lr': [9.6e-05, 9.6e-05], 'samples/contexts': 49408, 'samples/tokens': 12648448, 'gradient_steps': 192, 'loss/train': 43.367881774902344}\n",
      "{'lr': [9.65e-05, 9.65e-05], 'samples/contexts': 49664, 'samples/tokens': 12713984, 'gradient_steps': 193, 'loss/train': 42.27051544189453}\n",
      "{'lr': [9.7e-05, 9.7e-05], 'samples/contexts': 49920, 'samples/tokens': 12779520, 'gradient_steps': 194, 'loss/train': 43.97450256347656}\n",
      "{'lr': [9.750000000000001e-05, 9.750000000000001e-05], 'samples/contexts': 50176, 'samples/tokens': 12845056, 'gradient_steps': 195, 'loss/train': 44.90291213989258}\n",
      "{'lr': [9.800000000000001e-05, 9.800000000000001e-05], 'samples/contexts': 50432, 'samples/tokens': 12910592, 'gradient_steps': 196, 'loss/train': 43.29480743408203}\n",
      "{'lr': [9.850000000000001e-05, 9.850000000000001e-05], 'samples/contexts': 50688, 'samples/tokens': 12976128, 'gradient_steps': 197, 'loss/train': 44.526344299316406}\n",
      "{'lr': [9.900000000000001e-05, 9.900000000000001e-05], 'samples/contexts': 50944, 'samples/tokens': 13041664, 'gradient_steps': 198, 'loss/train': 43.904457092285156}\n",
      "{'lr': [9.95e-05, 9.95e-05], 'samples/contexts': 51200, 'samples/tokens': 13107200, 'gradient_steps': 199, 'loss/train': 44.11162567138672}\n",
      "{'lr': [0.0001, 0.0001], 'samples/contexts': 51456, 'samples/tokens': 13172736, 'gradient_steps': 200, 'loss/train': 44.4889030456543}\n",
      "{'lr': [0.0001005, 0.0001005], 'samples/contexts': 51712, 'samples/tokens': 13238272, 'gradient_steps': 201, 'loss/train': 44.534446716308594}\n",
      "{'lr': [0.000101, 0.000101], 'samples/contexts': 51968, 'samples/tokens': 13303808, 'gradient_steps': 202, 'loss/train': 44.82117462158203}\n",
      "{'lr': [0.00010150000000000001, 0.00010150000000000001], 'samples/contexts': 52224, 'samples/tokens': 13369344, 'gradient_steps': 203, 'loss/train': 41.92603302001953}\n",
      "{'lr': [0.000102, 0.000102], 'samples/contexts': 52480, 'samples/tokens': 13434880, 'gradient_steps': 204, 'loss/train': 44.11237716674805}\n",
      "{'lr': [0.0001025, 0.0001025], 'samples/contexts': 52736, 'samples/tokens': 13500416, 'gradient_steps': 205, 'loss/train': 44.384605407714844}\n",
      "{'lr': [0.000103, 0.000103], 'samples/contexts': 52992, 'samples/tokens': 13565952, 'gradient_steps': 206, 'loss/train': 44.53289794921875}\n",
      "{'lr': [0.0001035, 0.0001035], 'samples/contexts': 53248, 'samples/tokens': 13631488, 'gradient_steps': 207, 'loss/train': 42.799163818359375}\n",
      "{'lr': [0.000104, 0.000104], 'samples/contexts': 53504, 'samples/tokens': 13697024, 'gradient_steps': 208, 'loss/train': 43.83132553100586}\n",
      "{'lr': [0.00010449999999999999, 0.00010449999999999999], 'samples/contexts': 53760, 'samples/tokens': 13762560, 'gradient_steps': 209, 'loss/train': 41.45805740356445}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e928962a024fa8b7e40ca396762d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.57998514175415, 'perplexity': 720.5286254882812}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.000105, 0.000105], 'samples/contexts': 54016, 'samples/tokens': 13828096, 'gradient_steps': 210, 'loss/train': 44.20814895629883}\n",
      "{'lr': [0.0001055, 0.0001055], 'samples/contexts': 54272, 'samples/tokens': 13893632, 'gradient_steps': 211, 'loss/train': 44.350982666015625}\n",
      "{'lr': [0.000106, 0.000106], 'samples/contexts': 54528, 'samples/tokens': 13959168, 'gradient_steps': 212, 'loss/train': 43.619354248046875}\n",
      "{'lr': [0.0001065, 0.0001065], 'samples/contexts': 54784, 'samples/tokens': 14024704, 'gradient_steps': 213, 'loss/train': 43.702110290527344}\n",
      "{'lr': [0.000107, 0.000107], 'samples/contexts': 55040, 'samples/tokens': 14090240, 'gradient_steps': 214, 'loss/train': 41.55384063720703}\n",
      "{'lr': [0.0001075, 0.0001075], 'samples/contexts': 55296, 'samples/tokens': 14155776, 'gradient_steps': 215, 'loss/train': 43.743412017822266}\n",
      "{'lr': [0.000108, 0.000108], 'samples/contexts': 55552, 'samples/tokens': 14221312, 'gradient_steps': 216, 'loss/train': 43.105079650878906}\n",
      "{'lr': [0.00010850000000000001, 0.00010850000000000001], 'samples/contexts': 55808, 'samples/tokens': 14286848, 'gradient_steps': 217, 'loss/train': 42.47101593017578}\n",
      "{'lr': [0.000109, 0.000109], 'samples/contexts': 56064, 'samples/tokens': 14352384, 'gradient_steps': 218, 'loss/train': 42.793212890625}\n",
      "{'lr': [0.0001095, 0.0001095], 'samples/contexts': 56320, 'samples/tokens': 14417920, 'gradient_steps': 219, 'loss/train': 42.882347106933594}\n",
      "{'lr': [0.00011, 0.00011], 'samples/contexts': 56576, 'samples/tokens': 14483456, 'gradient_steps': 220, 'loss/train': 43.05110168457031}\n",
      "{'lr': [0.0001105, 0.0001105], 'samples/contexts': 56832, 'samples/tokens': 14548992, 'gradient_steps': 221, 'loss/train': 42.50407409667969}\n",
      "{'lr': [0.000111, 0.000111], 'samples/contexts': 57088, 'samples/tokens': 14614528, 'gradient_steps': 222, 'loss/train': 43.254638671875}\n",
      "{'lr': [0.0001115, 0.0001115], 'samples/contexts': 57344, 'samples/tokens': 14680064, 'gradient_steps': 223, 'loss/train': 42.887855529785156}\n",
      "{'lr': [0.000112, 0.000112], 'samples/contexts': 57600, 'samples/tokens': 14745600, 'gradient_steps': 224, 'loss/train': 42.9604377746582}\n",
      "{'lr': [0.00011250000000000001, 0.00011250000000000001], 'samples/contexts': 57856, 'samples/tokens': 14811136, 'gradient_steps': 225, 'loss/train': 43.44797134399414}\n",
      "{'lr': [0.00011300000000000001, 0.00011300000000000001], 'samples/contexts': 58112, 'samples/tokens': 14876672, 'gradient_steps': 226, 'loss/train': 42.825477600097656}\n",
      "{'lr': [0.00011350000000000001, 0.00011350000000000001], 'samples/contexts': 58368, 'samples/tokens': 14942208, 'gradient_steps': 227, 'loss/train': 42.47850036621094}\n",
      "{'lr': [0.000114, 0.000114], 'samples/contexts': 58624, 'samples/tokens': 15007744, 'gradient_steps': 228, 'loss/train': 43.74175262451172}\n",
      "{'lr': [0.0001145, 0.0001145], 'samples/contexts': 58880, 'samples/tokens': 15073280, 'gradient_steps': 229, 'loss/train': 43.48414993286133}\n",
      "{'lr': [0.000115, 0.000115], 'samples/contexts': 59136, 'samples/tokens': 15138816, 'gradient_steps': 230, 'loss/train': 42.60237121582031}\n",
      "{'lr': [0.0001155, 0.0001155], 'samples/contexts': 59392, 'samples/tokens': 15204352, 'gradient_steps': 231, 'loss/train': 42.898048400878906}\n",
      "{'lr': [0.00011600000000000001, 0.00011600000000000001], 'samples/contexts': 59648, 'samples/tokens': 15269888, 'gradient_steps': 232, 'loss/train': 42.75223159790039}\n",
      "{'lr': [0.00011650000000000001, 0.00011650000000000001], 'samples/contexts': 59904, 'samples/tokens': 15335424, 'gradient_steps': 233, 'loss/train': 43.084197998046875}\n",
      "{'lr': [0.00011700000000000001, 0.00011700000000000001], 'samples/contexts': 60160, 'samples/tokens': 15400960, 'gradient_steps': 234, 'loss/train': 40.899070739746094}\n",
      "{'lr': [0.0001175, 0.0001175], 'samples/contexts': 60416, 'samples/tokens': 15466496, 'gradient_steps': 235, 'loss/train': 43.24174880981445}\n",
      "{'lr': [0.000118, 0.000118], 'samples/contexts': 60672, 'samples/tokens': 15532032, 'gradient_steps': 236, 'loss/train': 41.03120422363281}\n",
      "{'lr': [0.0001185, 0.0001185], 'samples/contexts': 60928, 'samples/tokens': 15597568, 'gradient_steps': 237, 'loss/train': 41.70304870605469}\n",
      "{'lr': [0.00011899999999999999, 0.00011899999999999999], 'samples/contexts': 61184, 'samples/tokens': 15663104, 'gradient_steps': 238, 'loss/train': 42.26737976074219}\n",
      "{'lr': [0.00011949999999999999, 0.00011949999999999999], 'samples/contexts': 61440, 'samples/tokens': 15728640, 'gradient_steps': 239, 'loss/train': 43.302528381347656}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52283bb1e604431c94f0855d6cedce5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.442998886108398, 'perplexity': 628.2881469726562}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00012, 0.00012], 'samples/contexts': 61696, 'samples/tokens': 15794176, 'gradient_steps': 240, 'loss/train': 43.46315002441406}\n",
      "{'lr': [0.0001205, 0.0001205], 'samples/contexts': 61952, 'samples/tokens': 15859712, 'gradient_steps': 241, 'loss/train': 43.30318832397461}\n",
      "{'lr': [0.000121, 0.000121], 'samples/contexts': 62208, 'samples/tokens': 15925248, 'gradient_steps': 242, 'loss/train': 41.85728454589844}\n",
      "{'lr': [0.0001215, 0.0001215], 'samples/contexts': 62464, 'samples/tokens': 15990784, 'gradient_steps': 243, 'loss/train': 42.016998291015625}\n",
      "{'lr': [0.000122, 0.000122], 'samples/contexts': 62720, 'samples/tokens': 16056320, 'gradient_steps': 244, 'loss/train': 42.71946334838867}\n",
      "{'lr': [0.0001225, 0.0001225], 'samples/contexts': 62976, 'samples/tokens': 16121856, 'gradient_steps': 245, 'loss/train': 43.09562683105469}\n",
      "{'lr': [0.000123, 0.000123], 'samples/contexts': 63232, 'samples/tokens': 16187392, 'gradient_steps': 246, 'loss/train': 42.587913513183594}\n",
      "{'lr': [0.0001235, 0.0001235], 'samples/contexts': 63488, 'samples/tokens': 16252928, 'gradient_steps': 247, 'loss/train': 42.66371154785156}\n",
      "{'lr': [0.000124, 0.000124], 'samples/contexts': 63744, 'samples/tokens': 16318464, 'gradient_steps': 248, 'loss/train': 43.321083068847656}\n",
      "{'lr': [0.0001245, 0.0001245], 'samples/contexts': 64000, 'samples/tokens': 16384000, 'gradient_steps': 249, 'loss/train': 42.519779205322266}\n",
      "{'lr': [0.000125, 0.000125], 'samples/contexts': 64256, 'samples/tokens': 16449536, 'gradient_steps': 250, 'loss/train': 42.147315979003906}\n",
      "{'lr': [0.00012550000000000001, 0.00012550000000000001], 'samples/contexts': 64512, 'samples/tokens': 16515072, 'gradient_steps': 251, 'loss/train': 43.714012145996094}\n",
      "{'lr': [0.000126, 0.000126], 'samples/contexts': 64768, 'samples/tokens': 16580608, 'gradient_steps': 252, 'loss/train': 42.13872528076172}\n",
      "{'lr': [0.0001265, 0.0001265], 'samples/contexts': 65024, 'samples/tokens': 16646144, 'gradient_steps': 253, 'loss/train': 42.75476837158203}\n",
      "{'lr': [0.000127, 0.000127], 'samples/contexts': 65280, 'samples/tokens': 16711680, 'gradient_steps': 254, 'loss/train': 40.21315002441406}\n",
      "{'lr': [0.0001275, 0.0001275], 'samples/contexts': 65536, 'samples/tokens': 16777216, 'gradient_steps': 255, 'loss/train': 41.95289611816406}\n",
      "{'lr': [0.000128, 0.000128], 'samples/contexts': 65792, 'samples/tokens': 16842752, 'gradient_steps': 256, 'loss/train': 41.67747116088867}\n",
      "{'lr': [0.0001285, 0.0001285], 'samples/contexts': 66048, 'samples/tokens': 16908288, 'gradient_steps': 257, 'loss/train': 41.66075134277344}\n",
      "{'lr': [0.00012900000000000002, 0.00012900000000000002], 'samples/contexts': 66304, 'samples/tokens': 16973824, 'gradient_steps': 258, 'loss/train': 42.908260345458984}\n",
      "{'lr': [0.0001295, 0.0001295], 'samples/contexts': 66560, 'samples/tokens': 17039360, 'gradient_steps': 259, 'loss/train': 43.60679626464844}\n",
      "{'lr': [0.00013000000000000002, 0.00013000000000000002], 'samples/contexts': 66816, 'samples/tokens': 17104896, 'gradient_steps': 260, 'loss/train': 41.515785217285156}\n",
      "{'lr': [0.0001305, 0.0001305], 'samples/contexts': 67072, 'samples/tokens': 17170432, 'gradient_steps': 261, 'loss/train': 40.9906005859375}\n",
      "{'lr': [0.000131, 0.000131], 'samples/contexts': 67328, 'samples/tokens': 17235968, 'gradient_steps': 262, 'loss/train': 44.33949279785156}\n",
      "{'lr': [0.0001315, 0.0001315], 'samples/contexts': 67584, 'samples/tokens': 17301504, 'gradient_steps': 263, 'loss/train': 41.428253173828125}\n",
      "{'lr': [0.000132, 0.000132], 'samples/contexts': 67840, 'samples/tokens': 17367040, 'gradient_steps': 264, 'loss/train': 43.42380905151367}\n",
      "{'lr': [0.00013250000000000002, 0.00013250000000000002], 'samples/contexts': 68096, 'samples/tokens': 17432576, 'gradient_steps': 265, 'loss/train': 42.88981628417969}\n",
      "{'lr': [0.000133, 0.000133], 'samples/contexts': 68352, 'samples/tokens': 17498112, 'gradient_steps': 266, 'loss/train': 42.40239715576172}\n",
      "{'lr': [0.00013350000000000002, 0.00013350000000000002], 'samples/contexts': 68608, 'samples/tokens': 17563648, 'gradient_steps': 267, 'loss/train': 41.30644989013672}\n",
      "{'lr': [0.000134, 0.000134], 'samples/contexts': 68864, 'samples/tokens': 17629184, 'gradient_steps': 268, 'loss/train': 40.952735900878906}\n",
      "{'lr': [0.00013450000000000002, 0.00013450000000000002], 'samples/contexts': 69120, 'samples/tokens': 17694720, 'gradient_steps': 269, 'loss/train': 42.669010162353516}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6198e7d388dc44a3b383b6ebd88d462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.312440395355225, 'perplexity': 551.388916015625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.000135, 0.000135], 'samples/contexts': 69376, 'samples/tokens': 17760256, 'gradient_steps': 270, 'loss/train': 41.61447525024414}\n",
      "{'lr': [0.00013550000000000001, 0.00013550000000000001], 'samples/contexts': 69632, 'samples/tokens': 17825792, 'gradient_steps': 271, 'loss/train': 42.551666259765625}\n",
      "{'lr': [0.00013600000000000003, 0.00013600000000000003], 'samples/contexts': 69888, 'samples/tokens': 17891328, 'gradient_steps': 272, 'loss/train': 41.69309616088867}\n",
      "{'lr': [0.0001365, 0.0001365], 'samples/contexts': 70144, 'samples/tokens': 17956864, 'gradient_steps': 273, 'loss/train': 42.94802474975586}\n",
      "{'lr': [0.00013700000000000002, 0.00013700000000000002], 'samples/contexts': 70400, 'samples/tokens': 18022400, 'gradient_steps': 274, 'loss/train': 41.05244064331055}\n",
      "{'lr': [0.0001375, 0.0001375], 'samples/contexts': 70656, 'samples/tokens': 18087936, 'gradient_steps': 275, 'loss/train': 41.59552764892578}\n",
      "{'lr': [0.00013800000000000002, 0.00013800000000000002], 'samples/contexts': 70912, 'samples/tokens': 18153472, 'gradient_steps': 276, 'loss/train': 41.365360260009766}\n",
      "{'lr': [0.0001385, 0.0001385], 'samples/contexts': 71168, 'samples/tokens': 18219008, 'gradient_steps': 277, 'loss/train': 40.651588439941406}\n",
      "{'lr': [0.00013900000000000002, 0.00013900000000000002], 'samples/contexts': 71424, 'samples/tokens': 18284544, 'gradient_steps': 278, 'loss/train': 40.70402908325195}\n",
      "{'lr': [0.0001395, 0.0001395], 'samples/contexts': 71680, 'samples/tokens': 18350080, 'gradient_steps': 279, 'loss/train': 40.5728645324707}\n",
      "{'lr': [0.00014000000000000001, 0.00014000000000000001], 'samples/contexts': 71936, 'samples/tokens': 18415616, 'gradient_steps': 280, 'loss/train': 41.15145492553711}\n",
      "{'lr': [0.00014050000000000003, 0.00014050000000000003], 'samples/contexts': 72192, 'samples/tokens': 18481152, 'gradient_steps': 281, 'loss/train': 41.266082763671875}\n",
      "{'lr': [0.00014099999999999998, 0.00014099999999999998], 'samples/contexts': 72448, 'samples/tokens': 18546688, 'gradient_steps': 282, 'loss/train': 40.94169616699219}\n",
      "{'lr': [0.0001415, 0.0001415], 'samples/contexts': 72704, 'samples/tokens': 18612224, 'gradient_steps': 283, 'loss/train': 41.99073028564453}\n",
      "{'lr': [0.00014199999999999998, 0.00014199999999999998], 'samples/contexts': 72960, 'samples/tokens': 18677760, 'gradient_steps': 284, 'loss/train': 42.010536193847656}\n",
      "{'lr': [0.0001425, 0.0001425], 'samples/contexts': 73216, 'samples/tokens': 18743296, 'gradient_steps': 285, 'loss/train': 42.36053466796875}\n",
      "{'lr': [0.00014299999999999998, 0.00014299999999999998], 'samples/contexts': 73472, 'samples/tokens': 18808832, 'gradient_steps': 286, 'loss/train': 42.53512954711914}\n",
      "{'lr': [0.0001435, 0.0001435], 'samples/contexts': 73728, 'samples/tokens': 18874368, 'gradient_steps': 287, 'loss/train': 41.19924545288086}\n",
      "{'lr': [0.000144, 0.000144], 'samples/contexts': 73984, 'samples/tokens': 18939904, 'gradient_steps': 288, 'loss/train': 42.338905334472656}\n",
      "{'lr': [0.0001445, 0.0001445], 'samples/contexts': 74240, 'samples/tokens': 19005440, 'gradient_steps': 289, 'loss/train': 41.528038024902344}\n",
      "{'lr': [0.000145, 0.000145], 'samples/contexts': 74496, 'samples/tokens': 19070976, 'gradient_steps': 290, 'loss/train': 39.245216369628906}\n",
      "{'lr': [0.00014549999999999999, 0.00014549999999999999], 'samples/contexts': 74752, 'samples/tokens': 19136512, 'gradient_steps': 291, 'loss/train': 39.92948532104492}\n",
      "{'lr': [0.000146, 0.000146], 'samples/contexts': 75008, 'samples/tokens': 19202048, 'gradient_steps': 292, 'loss/train': 40.874366760253906}\n",
      "{'lr': [0.00014649999999999998, 0.00014649999999999998], 'samples/contexts': 75264, 'samples/tokens': 19267584, 'gradient_steps': 293, 'loss/train': 41.21134567260742}\n",
      "{'lr': [0.000147, 0.000147], 'samples/contexts': 75520, 'samples/tokens': 19333120, 'gradient_steps': 294, 'loss/train': 41.06537628173828}\n",
      "{'lr': [0.0001475, 0.0001475], 'samples/contexts': 75776, 'samples/tokens': 19398656, 'gradient_steps': 295, 'loss/train': 40.14671325683594}\n",
      "{'lr': [0.000148, 0.000148], 'samples/contexts': 76032, 'samples/tokens': 19464192, 'gradient_steps': 296, 'loss/train': 40.711181640625}\n",
      "{'lr': [0.0001485, 0.0001485], 'samples/contexts': 76288, 'samples/tokens': 19529728, 'gradient_steps': 297, 'loss/train': 41.55170440673828}\n",
      "{'lr': [0.000149, 0.000149], 'samples/contexts': 76544, 'samples/tokens': 19595264, 'gradient_steps': 298, 'loss/train': 41.583919525146484}\n",
      "{'lr': [0.0001495, 0.0001495], 'samples/contexts': 76800, 'samples/tokens': 19660800, 'gradient_steps': 299, 'loss/train': 40.40827941894531}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45b7ef55d0b43c693a3b295e1c0d0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.202305316925049, 'perplexity': 493.8863220214844}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00015, 0.00015], 'samples/contexts': 77056, 'samples/tokens': 19726336, 'gradient_steps': 300, 'loss/train': 40.61223602294922}\n",
      "{'lr': [0.0001505, 0.0001505], 'samples/contexts': 77312, 'samples/tokens': 19791872, 'gradient_steps': 301, 'loss/train': 42.06130599975586}\n",
      "{'lr': [0.000151, 0.000151], 'samples/contexts': 77568, 'samples/tokens': 19857408, 'gradient_steps': 302, 'loss/train': 42.35646057128906}\n",
      "{'lr': [0.0001515, 0.0001515], 'samples/contexts': 77824, 'samples/tokens': 19922944, 'gradient_steps': 303, 'loss/train': 40.227012634277344}\n",
      "{'lr': [0.000152, 0.000152], 'samples/contexts': 78080, 'samples/tokens': 19988480, 'gradient_steps': 304, 'loss/train': 41.29930877685547}\n",
      "{'lr': [0.0001525, 0.0001525], 'samples/contexts': 78336, 'samples/tokens': 20054016, 'gradient_steps': 305, 'loss/train': 40.63396453857422}\n",
      "{'lr': [0.000153, 0.000153], 'samples/contexts': 78592, 'samples/tokens': 20119552, 'gradient_steps': 306, 'loss/train': 41.05976867675781}\n",
      "{'lr': [0.0001535, 0.0001535], 'samples/contexts': 78848, 'samples/tokens': 20185088, 'gradient_steps': 307, 'loss/train': 41.510040283203125}\n",
      "{'lr': [0.000154, 0.000154], 'samples/contexts': 79104, 'samples/tokens': 20250624, 'gradient_steps': 308, 'loss/train': 40.807735443115234}\n",
      "{'lr': [0.00015450000000000001, 0.00015450000000000001], 'samples/contexts': 79360, 'samples/tokens': 20316160, 'gradient_steps': 309, 'loss/train': 40.97408676147461}\n",
      "{'lr': [0.000155, 0.000155], 'samples/contexts': 79616, 'samples/tokens': 20381696, 'gradient_steps': 310, 'loss/train': 41.77544403076172}\n",
      "{'lr': [0.0001555, 0.0001555], 'samples/contexts': 79872, 'samples/tokens': 20447232, 'gradient_steps': 311, 'loss/train': 41.464656829833984}\n",
      "{'lr': [0.000156, 0.000156], 'samples/contexts': 80128, 'samples/tokens': 20512768, 'gradient_steps': 312, 'loss/train': 41.128448486328125}\n",
      "{'lr': [0.0001565, 0.0001565], 'samples/contexts': 80384, 'samples/tokens': 20578304, 'gradient_steps': 313, 'loss/train': 40.27558898925781}\n",
      "{'lr': [0.000157, 0.000157], 'samples/contexts': 80640, 'samples/tokens': 20643840, 'gradient_steps': 314, 'loss/train': 40.412567138671875}\n",
      "{'lr': [0.0001575, 0.0001575], 'samples/contexts': 80896, 'samples/tokens': 20709376, 'gradient_steps': 315, 'loss/train': 40.03318405151367}\n",
      "{'lr': [0.000158, 0.000158], 'samples/contexts': 81152, 'samples/tokens': 20774912, 'gradient_steps': 316, 'loss/train': 39.75191879272461}\n",
      "{'lr': [0.0001585, 0.0001585], 'samples/contexts': 81408, 'samples/tokens': 20840448, 'gradient_steps': 317, 'loss/train': 41.80613327026367}\n",
      "{'lr': [0.00015900000000000002, 0.00015900000000000002], 'samples/contexts': 81664, 'samples/tokens': 20905984, 'gradient_steps': 318, 'loss/train': 40.782203674316406}\n",
      "{'lr': [0.0001595, 0.0001595], 'samples/contexts': 81920, 'samples/tokens': 20971520, 'gradient_steps': 319, 'loss/train': 39.82806396484375}\n",
      "{'lr': [0.00016, 0.00016], 'samples/contexts': 82176, 'samples/tokens': 21037056, 'gradient_steps': 320, 'loss/train': 40.175498962402344}\n",
      "{'lr': [0.0001605, 0.0001605], 'samples/contexts': 82432, 'samples/tokens': 21102592, 'gradient_steps': 321, 'loss/train': 40.1192626953125}\n",
      "{'lr': [0.000161, 0.000161], 'samples/contexts': 82688, 'samples/tokens': 21168128, 'gradient_steps': 322, 'loss/train': 40.664955139160156}\n",
      "{'lr': [0.0001615, 0.0001615], 'samples/contexts': 82944, 'samples/tokens': 21233664, 'gradient_steps': 323, 'loss/train': 40.34394073486328}\n",
      "{'lr': [0.000162, 0.000162], 'samples/contexts': 83200, 'samples/tokens': 21299200, 'gradient_steps': 324, 'loss/train': 40.452674865722656}\n",
      "{'lr': [0.00016250000000000002, 0.00016250000000000002], 'samples/contexts': 83456, 'samples/tokens': 21364736, 'gradient_steps': 325, 'loss/train': 40.514793395996094}\n",
      "{'lr': [0.000163, 0.000163], 'samples/contexts': 83712, 'samples/tokens': 21430272, 'gradient_steps': 326, 'loss/train': 40.31709289550781}\n",
      "{'lr': [0.00016350000000000002, 0.00016350000000000002], 'samples/contexts': 83968, 'samples/tokens': 21495808, 'gradient_steps': 327, 'loss/train': 39.88347625732422}\n",
      "{'lr': [0.000164, 0.000164], 'samples/contexts': 84224, 'samples/tokens': 21561344, 'gradient_steps': 328, 'loss/train': 39.700477600097656}\n",
      "{'lr': [0.00016450000000000001, 0.00016450000000000001], 'samples/contexts': 84480, 'samples/tokens': 21626880, 'gradient_steps': 329, 'loss/train': 40.28202819824219}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce120301cd5c47cd8c14441429b44fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.115078926086426, 'perplexity': 452.6317443847656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.000165, 0.000165], 'samples/contexts': 84736, 'samples/tokens': 21692416, 'gradient_steps': 330, 'loss/train': 39.905372619628906}\n",
      "{'lr': [0.0001655, 0.0001655], 'samples/contexts': 84992, 'samples/tokens': 21757952, 'gradient_steps': 331, 'loss/train': 39.95137023925781}\n",
      "{'lr': [0.00016600000000000002, 0.00016600000000000002], 'samples/contexts': 85248, 'samples/tokens': 21823488, 'gradient_steps': 332, 'loss/train': 40.25444793701172}\n",
      "{'lr': [0.0001665, 0.0001665], 'samples/contexts': 85504, 'samples/tokens': 21889024, 'gradient_steps': 333, 'loss/train': 39.74456024169922}\n",
      "{'lr': [0.00016700000000000002, 0.00016700000000000002], 'samples/contexts': 85760, 'samples/tokens': 21954560, 'gradient_steps': 334, 'loss/train': 41.021400451660156}\n",
      "{'lr': [0.0001675, 0.0001675], 'samples/contexts': 86016, 'samples/tokens': 22020096, 'gradient_steps': 335, 'loss/train': 40.270545959472656}\n",
      "{'lr': [0.00016800000000000002, 0.00016800000000000002], 'samples/contexts': 86272, 'samples/tokens': 22085632, 'gradient_steps': 336, 'loss/train': 40.55177307128906}\n",
      "{'lr': [0.0001685, 0.0001685], 'samples/contexts': 86528, 'samples/tokens': 22151168, 'gradient_steps': 337, 'loss/train': 41.81910705566406}\n",
      "{'lr': [0.00016900000000000002, 0.00016900000000000002], 'samples/contexts': 86784, 'samples/tokens': 22216704, 'gradient_steps': 338, 'loss/train': 39.93659973144531}\n",
      "{'lr': [0.00016950000000000003, 0.00016950000000000003], 'samples/contexts': 87040, 'samples/tokens': 22282240, 'gradient_steps': 339, 'loss/train': 40.02630615234375}\n",
      "{'lr': [0.00017, 0.00017], 'samples/contexts': 87296, 'samples/tokens': 22347776, 'gradient_steps': 340, 'loss/train': 40.971797943115234}\n",
      "{'lr': [0.00017050000000000002, 0.00017050000000000002], 'samples/contexts': 87552, 'samples/tokens': 22413312, 'gradient_steps': 341, 'loss/train': 39.95000457763672}\n",
      "{'lr': [0.000171, 0.000171], 'samples/contexts': 87808, 'samples/tokens': 22478848, 'gradient_steps': 342, 'loss/train': 39.03721237182617}\n",
      "{'lr': [0.00017150000000000002, 0.00017150000000000002], 'samples/contexts': 88064, 'samples/tokens': 22544384, 'gradient_steps': 343, 'loss/train': 39.648094177246094}\n",
      "{'lr': [0.00017199999999999998, 0.00017199999999999998], 'samples/contexts': 88320, 'samples/tokens': 22609920, 'gradient_steps': 344, 'loss/train': 39.54566955566406}\n",
      "{'lr': [0.0001725, 0.0001725], 'samples/contexts': 88576, 'samples/tokens': 22675456, 'gradient_steps': 345, 'loss/train': 40.164608001708984}\n",
      "{'lr': [0.000173, 0.000173], 'samples/contexts': 88832, 'samples/tokens': 22740992, 'gradient_steps': 346, 'loss/train': 39.35847473144531}\n",
      "{'lr': [0.0001735, 0.0001735], 'samples/contexts': 89088, 'samples/tokens': 22806528, 'gradient_steps': 347, 'loss/train': 40.29038619995117}\n",
      "{'lr': [0.000174, 0.000174], 'samples/contexts': 89344, 'samples/tokens': 22872064, 'gradient_steps': 348, 'loss/train': 40.103641510009766}\n",
      "{'lr': [0.00017449999999999999, 0.00017449999999999999], 'samples/contexts': 89600, 'samples/tokens': 22937600, 'gradient_steps': 349, 'loss/train': 39.41468048095703}\n",
      "{'lr': [0.000175, 0.000175], 'samples/contexts': 89856, 'samples/tokens': 23003136, 'gradient_steps': 350, 'loss/train': 39.57002258300781}\n",
      "{'lr': [0.00017549999999999998, 0.00017549999999999998], 'samples/contexts': 90112, 'samples/tokens': 23068672, 'gradient_steps': 351, 'loss/train': 39.24451446533203}\n",
      "{'lr': [0.000176, 0.000176], 'samples/contexts': 90368, 'samples/tokens': 23134208, 'gradient_steps': 352, 'loss/train': 39.370994567871094}\n",
      "{'lr': [0.00017649999999999998, 0.00017649999999999998], 'samples/contexts': 90624, 'samples/tokens': 23199744, 'gradient_steps': 353, 'loss/train': 38.1583366394043}\n",
      "{'lr': [0.000177, 0.000177], 'samples/contexts': 90880, 'samples/tokens': 23265280, 'gradient_steps': 354, 'loss/train': 39.48231887817383}\n",
      "{'lr': [0.0001775, 0.0001775], 'samples/contexts': 91136, 'samples/tokens': 23330816, 'gradient_steps': 355, 'loss/train': 39.78419494628906}\n",
      "{'lr': [0.000178, 0.000178], 'samples/contexts': 91392, 'samples/tokens': 23396352, 'gradient_steps': 356, 'loss/train': 40.42517852783203}\n",
      "{'lr': [0.0001785, 0.0001785], 'samples/contexts': 91648, 'samples/tokens': 23461888, 'gradient_steps': 357, 'loss/train': 40.70610809326172}\n",
      "{'lr': [0.000179, 0.000179], 'samples/contexts': 91904, 'samples/tokens': 23527424, 'gradient_steps': 358, 'loss/train': 39.88035583496094}\n",
      "{'lr': [0.0001795, 0.0001795], 'samples/contexts': 92160, 'samples/tokens': 23592960, 'gradient_steps': 359, 'loss/train': 41.14142608642578}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4608985b724856aa77047d1ce454aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 6.023135662078857, 'perplexity': 412.8711853027344}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00017999999999999998, 0.00017999999999999998], 'samples/contexts': 92416, 'samples/tokens': 23658496, 'gradient_steps': 360, 'loss/train': 40.13685607910156}\n",
      "{'lr': [0.0001805, 0.0001805], 'samples/contexts': 92672, 'samples/tokens': 23724032, 'gradient_steps': 361, 'loss/train': 39.8623161315918}\n",
      "{'lr': [0.000181, 0.000181], 'samples/contexts': 92928, 'samples/tokens': 23789568, 'gradient_steps': 362, 'loss/train': 40.77336502075195}\n",
      "{'lr': [0.0001815, 0.0001815], 'samples/contexts': 93184, 'samples/tokens': 23855104, 'gradient_steps': 363, 'loss/train': 39.20796203613281}\n",
      "{'lr': [0.000182, 0.000182], 'samples/contexts': 93440, 'samples/tokens': 23920640, 'gradient_steps': 364, 'loss/train': 39.72557067871094}\n",
      "{'lr': [0.0001825, 0.0001825], 'samples/contexts': 93696, 'samples/tokens': 23986176, 'gradient_steps': 365, 'loss/train': 39.38744354248047}\n",
      "{'lr': [0.000183, 0.000183], 'samples/contexts': 93952, 'samples/tokens': 24051712, 'gradient_steps': 366, 'loss/train': 39.76262664794922}\n",
      "{'lr': [0.0001835, 0.0001835], 'samples/contexts': 94208, 'samples/tokens': 24117248, 'gradient_steps': 367, 'loss/train': 39.813419342041016}\n",
      "{'lr': [0.000184, 0.000184], 'samples/contexts': 94464, 'samples/tokens': 24182784, 'gradient_steps': 368, 'loss/train': 39.74481201171875}\n",
      "{'lr': [0.0001845, 0.0001845], 'samples/contexts': 94720, 'samples/tokens': 24248320, 'gradient_steps': 369, 'loss/train': 40.70026397705078}\n",
      "{'lr': [0.000185, 0.000185], 'samples/contexts': 94976, 'samples/tokens': 24313856, 'gradient_steps': 370, 'loss/train': 38.15932083129883}\n",
      "{'lr': [0.0001855, 0.0001855], 'samples/contexts': 95232, 'samples/tokens': 24379392, 'gradient_steps': 371, 'loss/train': 39.88530731201172}\n",
      "{'lr': [0.000186, 0.000186], 'samples/contexts': 95488, 'samples/tokens': 24444928, 'gradient_steps': 372, 'loss/train': 38.70405578613281}\n",
      "{'lr': [0.0001865, 0.0001865], 'samples/contexts': 95744, 'samples/tokens': 24510464, 'gradient_steps': 373, 'loss/train': 39.159324645996094}\n",
      "{'lr': [0.000187, 0.000187], 'samples/contexts': 96000, 'samples/tokens': 24576000, 'gradient_steps': 374, 'loss/train': 39.12663650512695}\n",
      "{'lr': [0.0001875, 0.0001875], 'samples/contexts': 96256, 'samples/tokens': 24641536, 'gradient_steps': 375, 'loss/train': 39.936302185058594}\n",
      "{'lr': [0.00018800000000000002, 0.00018800000000000002], 'samples/contexts': 96512, 'samples/tokens': 24707072, 'gradient_steps': 376, 'loss/train': 38.44674301147461}\n",
      "{'lr': [0.0001885, 0.0001885], 'samples/contexts': 96768, 'samples/tokens': 24772608, 'gradient_steps': 377, 'loss/train': 41.496604919433594}\n",
      "{'lr': [0.000189, 0.000189], 'samples/contexts': 97024, 'samples/tokens': 24838144, 'gradient_steps': 378, 'loss/train': 39.89036178588867}\n",
      "{'lr': [0.0001895, 0.0001895], 'samples/contexts': 97280, 'samples/tokens': 24903680, 'gradient_steps': 379, 'loss/train': 39.172977447509766}\n",
      "{'lr': [0.00019, 0.00019], 'samples/contexts': 97536, 'samples/tokens': 24969216, 'gradient_steps': 380, 'loss/train': 39.590248107910156}\n",
      "{'lr': [0.0001905, 0.0001905], 'samples/contexts': 97792, 'samples/tokens': 25034752, 'gradient_steps': 381, 'loss/train': 39.822322845458984}\n",
      "{'lr': [0.000191, 0.000191], 'samples/contexts': 98048, 'samples/tokens': 25100288, 'gradient_steps': 382, 'loss/train': 38.46446228027344}\n",
      "{'lr': [0.00019150000000000002, 0.00019150000000000002], 'samples/contexts': 98304, 'samples/tokens': 25165824, 'gradient_steps': 383, 'loss/train': 38.71469497680664}\n",
      "{'lr': [0.000192, 0.000192], 'samples/contexts': 98560, 'samples/tokens': 25231360, 'gradient_steps': 384, 'loss/train': 40.925968170166016}\n",
      "{'lr': [0.00019250000000000002, 0.00019250000000000002], 'samples/contexts': 98816, 'samples/tokens': 25296896, 'gradient_steps': 385, 'loss/train': 38.97119903564453}\n",
      "{'lr': [0.000193, 0.000193], 'samples/contexts': 99072, 'samples/tokens': 25362432, 'gradient_steps': 386, 'loss/train': 38.60364532470703}\n",
      "{'lr': [0.00019350000000000001, 0.00019350000000000001], 'samples/contexts': 99328, 'samples/tokens': 25427968, 'gradient_steps': 387, 'loss/train': 38.81120300292969}\n",
      "{'lr': [0.000194, 0.000194], 'samples/contexts': 99584, 'samples/tokens': 25493504, 'gradient_steps': 388, 'loss/train': 39.266448974609375}\n",
      "{'lr': [0.0001945, 0.0001945], 'samples/contexts': 99840, 'samples/tokens': 25559040, 'gradient_steps': 389, 'loss/train': 39.563907623291016}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496ca95b2d3941d8a6ca592074a9c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 5.941521167755127, 'perplexity': 380.5133056640625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00019500000000000002, 0.00019500000000000002], 'samples/contexts': 100096, 'samples/tokens': 25624576, 'gradient_steps': 390, 'loss/train': 39.82495880126953}\n",
      "{'lr': [0.0001955, 0.0001955], 'samples/contexts': 100352, 'samples/tokens': 25690112, 'gradient_steps': 391, 'loss/train': 39.27484893798828}\n",
      "{'lr': [0.00019600000000000002, 0.00019600000000000002], 'samples/contexts': 100608, 'samples/tokens': 25755648, 'gradient_steps': 392, 'loss/train': 39.47488021850586}\n",
      "{'lr': [0.0001965, 0.0001965], 'samples/contexts': 100864, 'samples/tokens': 25821184, 'gradient_steps': 393, 'loss/train': 40.34943389892578}\n",
      "{'lr': [0.00019700000000000002, 0.00019700000000000002], 'samples/contexts': 101120, 'samples/tokens': 25886720, 'gradient_steps': 394, 'loss/train': 38.55377960205078}\n",
      "{'lr': [0.0001975, 0.0001975], 'samples/contexts': 101376, 'samples/tokens': 25952256, 'gradient_steps': 395, 'loss/train': 40.489173889160156}\n",
      "{'lr': [0.00019800000000000002, 0.00019800000000000002], 'samples/contexts': 101632, 'samples/tokens': 26017792, 'gradient_steps': 396, 'loss/train': 38.58583450317383}\n",
      "{'lr': [0.00019850000000000003, 0.00019850000000000003], 'samples/contexts': 101888, 'samples/tokens': 26083328, 'gradient_steps': 397, 'loss/train': 38.69084167480469}\n",
      "{'lr': [0.000199, 0.000199], 'samples/contexts': 102144, 'samples/tokens': 26148864, 'gradient_steps': 398, 'loss/train': 39.6595344543457}\n",
      "{'lr': [0.00019950000000000002, 0.00019950000000000002], 'samples/contexts': 102400, 'samples/tokens': 26214400, 'gradient_steps': 399, 'loss/train': 40.044822692871094}\n",
      "{'lr': [0.0002, 0.0002], 'samples/contexts': 102656, 'samples/tokens': 26279936, 'gradient_steps': 400, 'loss/train': 39.130165100097656}\n",
      "{'lr': [0.00020050000000000002, 0.00020050000000000002], 'samples/contexts': 102912, 'samples/tokens': 26345472, 'gradient_steps': 401, 'loss/train': 39.10697937011719}\n",
      "{'lr': [0.000201, 0.000201], 'samples/contexts': 103168, 'samples/tokens': 26411008, 'gradient_steps': 402, 'loss/train': 39.627410888671875}\n",
      "{'lr': [0.00020150000000000002, 0.00020150000000000002], 'samples/contexts': 103424, 'samples/tokens': 26476544, 'gradient_steps': 403, 'loss/train': 39.6717414855957}\n",
      "{'lr': [0.000202, 0.000202], 'samples/contexts': 103680, 'samples/tokens': 26542080, 'gradient_steps': 404, 'loss/train': 39.14708709716797}\n",
      "{'lr': [0.00020250000000000002, 0.00020250000000000002], 'samples/contexts': 103936, 'samples/tokens': 26607616, 'gradient_steps': 405, 'loss/train': 39.336490631103516}\n",
      "{'lr': [0.00020300000000000003, 0.00020300000000000003], 'samples/contexts': 104192, 'samples/tokens': 26673152, 'gradient_steps': 406, 'loss/train': 39.32293701171875}\n",
      "{'lr': [0.00020349999999999999, 0.00020349999999999999], 'samples/contexts': 104448, 'samples/tokens': 26738688, 'gradient_steps': 407, 'loss/train': 39.170902252197266}\n",
      "{'lr': [0.000204, 0.000204], 'samples/contexts': 104704, 'samples/tokens': 26804224, 'gradient_steps': 408, 'loss/train': 38.76200866699219}\n",
      "{'lr': [0.00020449999999999998, 0.00020449999999999998], 'samples/contexts': 104960, 'samples/tokens': 26869760, 'gradient_steps': 409, 'loss/train': 38.35231018066406}\n",
      "{'lr': [0.000205, 0.000205], 'samples/contexts': 105216, 'samples/tokens': 26935296, 'gradient_steps': 410, 'loss/train': 37.93256759643555}\n",
      "{'lr': [0.00020549999999999998, 0.00020549999999999998], 'samples/contexts': 105472, 'samples/tokens': 27000832, 'gradient_steps': 411, 'loss/train': 38.61794662475586}\n",
      "{'lr': [0.000206, 0.000206], 'samples/contexts': 105728, 'samples/tokens': 27066368, 'gradient_steps': 412, 'loss/train': 39.645851135253906}\n",
      "{'lr': [0.0002065, 0.0002065], 'samples/contexts': 105984, 'samples/tokens': 27131904, 'gradient_steps': 413, 'loss/train': 39.622108459472656}\n",
      "{'lr': [0.000207, 0.000207], 'samples/contexts': 106240, 'samples/tokens': 27197440, 'gradient_steps': 414, 'loss/train': 39.07829284667969}\n",
      "{'lr': [0.0002075, 0.0002075], 'samples/contexts': 106496, 'samples/tokens': 27262976, 'gradient_steps': 415, 'loss/train': 38.93468475341797}\n",
      "{'lr': [0.000208, 0.000208], 'samples/contexts': 106752, 'samples/tokens': 27328512, 'gradient_steps': 416, 'loss/train': 38.94631576538086}\n",
      "{'lr': [0.0002085, 0.0002085], 'samples/contexts': 107008, 'samples/tokens': 27394048, 'gradient_steps': 417, 'loss/train': 38.54541015625}\n",
      "{'lr': [0.00020899999999999998, 0.00020899999999999998], 'samples/contexts': 107264, 'samples/tokens': 27459584, 'gradient_steps': 418, 'loss/train': 39.04315185546875}\n",
      "{'lr': [0.0002095, 0.0002095], 'samples/contexts': 107520, 'samples/tokens': 27525120, 'gradient_steps': 419, 'loss/train': 38.824153900146484}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339dc439c6004f5798d219142d7604fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 5.853573322296143, 'perplexity': 348.4773864746094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00021, 0.00021], 'samples/contexts': 107776, 'samples/tokens': 27590656, 'gradient_steps': 420, 'loss/train': 38.40015411376953}\n",
      "{'lr': [0.0002105, 0.0002105], 'samples/contexts': 108032, 'samples/tokens': 27656192, 'gradient_steps': 421, 'loss/train': 38.650978088378906}\n",
      "{'lr': [0.000211, 0.000211], 'samples/contexts': 108288, 'samples/tokens': 27721728, 'gradient_steps': 422, 'loss/train': 38.469512939453125}\n",
      "{'lr': [0.0002115, 0.0002115], 'samples/contexts': 108544, 'samples/tokens': 27787264, 'gradient_steps': 423, 'loss/train': 38.78327178955078}\n",
      "{'lr': [0.000212, 0.000212], 'samples/contexts': 108800, 'samples/tokens': 27852800, 'gradient_steps': 424, 'loss/train': 39.07328414916992}\n",
      "{'lr': [0.0002125, 0.0002125], 'samples/contexts': 109056, 'samples/tokens': 27918336, 'gradient_steps': 425, 'loss/train': 38.0362548828125}\n",
      "{'lr': [0.000213, 0.000213], 'samples/contexts': 109312, 'samples/tokens': 27983872, 'gradient_steps': 426, 'loss/train': 38.538177490234375}\n",
      "{'lr': [0.0002135, 0.0002135], 'samples/contexts': 109568, 'samples/tokens': 28049408, 'gradient_steps': 427, 'loss/train': 38.249305725097656}\n",
      "{'lr': [0.000214, 0.000214], 'samples/contexts': 109824, 'samples/tokens': 28114944, 'gradient_steps': 428, 'loss/train': 38.35755920410156}\n",
      "{'lr': [0.0002145, 0.0002145], 'samples/contexts': 110080, 'samples/tokens': 28180480, 'gradient_steps': 429, 'loss/train': 39.090240478515625}\n",
      "{'lr': [0.000215, 0.000215], 'samples/contexts': 110336, 'samples/tokens': 28246016, 'gradient_steps': 430, 'loss/train': 39.79894256591797}\n",
      "{'lr': [0.0002155, 0.0002155], 'samples/contexts': 110592, 'samples/tokens': 28311552, 'gradient_steps': 431, 'loss/train': 38.770668029785156}\n",
      "{'lr': [0.000216, 0.000216], 'samples/contexts': 110848, 'samples/tokens': 28377088, 'gradient_steps': 432, 'loss/train': 38.28910827636719}\n",
      "{'lr': [0.0002165, 0.0002165], 'samples/contexts': 111104, 'samples/tokens': 28442624, 'gradient_steps': 433, 'loss/train': 38.318275451660156}\n",
      "{'lr': [0.00021700000000000002, 0.00021700000000000002], 'samples/contexts': 111360, 'samples/tokens': 28508160, 'gradient_steps': 434, 'loss/train': 37.635860443115234}\n",
      "{'lr': [0.0002175, 0.0002175], 'samples/contexts': 111616, 'samples/tokens': 28573696, 'gradient_steps': 435, 'loss/train': 38.173404693603516}\n",
      "{'lr': [0.000218, 0.000218], 'samples/contexts': 111872, 'samples/tokens': 28639232, 'gradient_steps': 436, 'loss/train': 38.353946685791016}\n",
      "{'lr': [0.0002185, 0.0002185], 'samples/contexts': 112128, 'samples/tokens': 28704768, 'gradient_steps': 437, 'loss/train': 39.038814544677734}\n",
      "{'lr': [0.000219, 0.000219], 'samples/contexts': 112384, 'samples/tokens': 28770304, 'gradient_steps': 438, 'loss/train': 37.462127685546875}\n",
      "{'lr': [0.0002195, 0.0002195], 'samples/contexts': 112640, 'samples/tokens': 28835840, 'gradient_steps': 439, 'loss/train': 36.90202713012695}\n",
      "{'lr': [0.00022, 0.00022], 'samples/contexts': 112896, 'samples/tokens': 28901376, 'gradient_steps': 440, 'loss/train': 38.16779327392578}\n",
      "{'lr': [0.0002205, 0.0002205], 'samples/contexts': 113152, 'samples/tokens': 28966912, 'gradient_steps': 441, 'loss/train': 38.517173767089844}\n",
      "{'lr': [0.000221, 0.000221], 'samples/contexts': 113408, 'samples/tokens': 29032448, 'gradient_steps': 442, 'loss/train': 38.44951629638672}\n",
      "{'lr': [0.00022150000000000002, 0.00022150000000000002], 'samples/contexts': 113664, 'samples/tokens': 29097984, 'gradient_steps': 443, 'loss/train': 37.80535888671875}\n",
      "{'lr': [0.000222, 0.000222], 'samples/contexts': 113920, 'samples/tokens': 29163520, 'gradient_steps': 444, 'loss/train': 38.69659423828125}\n",
      "{'lr': [0.00022250000000000001, 0.00022250000000000001], 'samples/contexts': 114176, 'samples/tokens': 29229056, 'gradient_steps': 445, 'loss/train': 39.08805847167969}\n",
      "{'lr': [0.000223, 0.000223], 'samples/contexts': 114432, 'samples/tokens': 29294592, 'gradient_steps': 446, 'loss/train': 39.20322036743164}\n",
      "{'lr': [0.0002235, 0.0002235], 'samples/contexts': 114688, 'samples/tokens': 29360128, 'gradient_steps': 447, 'loss/train': 37.308876037597656}\n",
      "{'lr': [0.000224, 0.000224], 'samples/contexts': 114944, 'samples/tokens': 29425664, 'gradient_steps': 448, 'loss/train': 38.785919189453125}\n",
      "{'lr': [0.0002245, 0.0002245], 'samples/contexts': 115200, 'samples/tokens': 29491200, 'gradient_steps': 449, 'loss/train': 38.01451110839844}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69883c1d36b4225a8d08577a2094788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 5.778227806091309, 'perplexity': 323.1859436035156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00022500000000000002, 0.00022500000000000002], 'samples/contexts': 115456, 'samples/tokens': 29556736, 'gradient_steps': 450, 'loss/train': 40.11278533935547}\n",
      "{'lr': [0.0002255, 0.0002255], 'samples/contexts': 115712, 'samples/tokens': 29622272, 'gradient_steps': 451, 'loss/train': 37.819244384765625}\n",
      "{'lr': [0.00022600000000000002, 0.00022600000000000002], 'samples/contexts': 115968, 'samples/tokens': 29687808, 'gradient_steps': 452, 'loss/train': 38.31676483154297}\n",
      "{'lr': [0.0002265, 0.0002265], 'samples/contexts': 116224, 'samples/tokens': 29753344, 'gradient_steps': 453, 'loss/train': 39.00597381591797}\n",
      "{'lr': [0.00022700000000000002, 0.00022700000000000002], 'samples/contexts': 116480, 'samples/tokens': 29818880, 'gradient_steps': 454, 'loss/train': 38.56154251098633}\n",
      "{'lr': [0.0002275, 0.0002275], 'samples/contexts': 116736, 'samples/tokens': 29884416, 'gradient_steps': 455, 'loss/train': 38.082969665527344}\n",
      "{'lr': [0.000228, 0.000228], 'samples/contexts': 116992, 'samples/tokens': 29949952, 'gradient_steps': 456, 'loss/train': 38.64683532714844}\n",
      "{'lr': [0.00022850000000000002, 0.00022850000000000002], 'samples/contexts': 117248, 'samples/tokens': 30015488, 'gradient_steps': 457, 'loss/train': 38.43238067626953}\n",
      "{'lr': [0.000229, 0.000229], 'samples/contexts': 117504, 'samples/tokens': 30081024, 'gradient_steps': 458, 'loss/train': 37.5352783203125}\n",
      "{'lr': [0.00022950000000000002, 0.00022950000000000002], 'samples/contexts': 117760, 'samples/tokens': 30146560, 'gradient_steps': 459, 'loss/train': 37.259971618652344}\n",
      "{'lr': [0.00023, 0.00023], 'samples/contexts': 118016, 'samples/tokens': 30212096, 'gradient_steps': 460, 'loss/train': 38.485084533691406}\n",
      "{'lr': [0.00023050000000000002, 0.00023050000000000002], 'samples/contexts': 118272, 'samples/tokens': 30277632, 'gradient_steps': 461, 'loss/train': 38.38526153564453}\n",
      "{'lr': [0.000231, 0.000231], 'samples/contexts': 118528, 'samples/tokens': 30343168, 'gradient_steps': 462, 'loss/train': 37.273109436035156}\n",
      "{'lr': [0.00023150000000000002, 0.00023150000000000002], 'samples/contexts': 118784, 'samples/tokens': 30408704, 'gradient_steps': 463, 'loss/train': 38.28916931152344}\n",
      "{'lr': [0.00023200000000000003, 0.00023200000000000003], 'samples/contexts': 119040, 'samples/tokens': 30474240, 'gradient_steps': 464, 'loss/train': 37.76945495605469}\n",
      "{'lr': [0.0002325, 0.0002325], 'samples/contexts': 119296, 'samples/tokens': 30539776, 'gradient_steps': 465, 'loss/train': 37.30478286743164}\n",
      "{'lr': [0.00023300000000000003, 0.00023300000000000003], 'samples/contexts': 119552, 'samples/tokens': 30605312, 'gradient_steps': 466, 'loss/train': 38.461212158203125}\n",
      "{'lr': [0.0002335, 0.0002335], 'samples/contexts': 119808, 'samples/tokens': 30670848, 'gradient_steps': 467, 'loss/train': 37.88189697265625}\n",
      "{'lr': [0.00023400000000000002, 0.00023400000000000002], 'samples/contexts': 120064, 'samples/tokens': 30736384, 'gradient_steps': 468, 'loss/train': 37.44601821899414}\n",
      "{'lr': [0.00023449999999999998, 0.00023449999999999998], 'samples/contexts': 120320, 'samples/tokens': 30801920, 'gradient_steps': 469, 'loss/train': 38.22028350830078}\n",
      "{'lr': [0.000235, 0.000235], 'samples/contexts': 120576, 'samples/tokens': 30867456, 'gradient_steps': 470, 'loss/train': 39.007904052734375}\n",
      "{'lr': [0.0002355, 0.0002355], 'samples/contexts': 120832, 'samples/tokens': 30932992, 'gradient_steps': 471, 'loss/train': 37.38547134399414}\n",
      "{'lr': [0.000236, 0.000236], 'samples/contexts': 121088, 'samples/tokens': 30998528, 'gradient_steps': 472, 'loss/train': 36.8974609375}\n",
      "{'lr': [0.0002365, 0.0002365], 'samples/contexts': 121344, 'samples/tokens': 31064064, 'gradient_steps': 473, 'loss/train': 37.919124603271484}\n",
      "{'lr': [0.000237, 0.000237], 'samples/contexts': 121600, 'samples/tokens': 31129600, 'gradient_steps': 474, 'loss/train': 37.58021545410156}\n",
      "{'lr': [0.0002375, 0.0002375], 'samples/contexts': 121856, 'samples/tokens': 31195136, 'gradient_steps': 475, 'loss/train': 37.98902130126953}\n",
      "{'lr': [0.00023799999999999998, 0.00023799999999999998], 'samples/contexts': 122112, 'samples/tokens': 31260672, 'gradient_steps': 476, 'loss/train': 38.61144256591797}\n",
      "{'lr': [0.0002385, 0.0002385], 'samples/contexts': 122368, 'samples/tokens': 31326208, 'gradient_steps': 477, 'loss/train': 37.68916320800781}\n",
      "{'lr': [0.00023899999999999998, 0.00023899999999999998], 'samples/contexts': 122624, 'samples/tokens': 31391744, 'gradient_steps': 478, 'loss/train': 37.7974853515625}\n",
      "{'lr': [0.0002395, 0.0002395], 'samples/contexts': 122880, 'samples/tokens': 31457280, 'gradient_steps': 479, 'loss/train': 38.136756896972656}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306215b79eea467291612cebb01e3214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 5.69384765625, 'perplexity': 297.0343322753906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.00024, 0.00024], 'samples/contexts': 123136, 'samples/tokens': 31522816, 'gradient_steps': 480, 'loss/train': 37.82728576660156}\n",
      "{'lr': [0.0002405, 0.0002405], 'samples/contexts': 123392, 'samples/tokens': 31588352, 'gradient_steps': 481, 'loss/train': 37.62151336669922}\n",
      "{'lr': [0.000241, 0.000241], 'samples/contexts': 123648, 'samples/tokens': 31653888, 'gradient_steps': 482, 'loss/train': 38.9891471862793}\n",
      "{'lr': [0.0002415, 0.0002415], 'samples/contexts': 123904, 'samples/tokens': 31719424, 'gradient_steps': 483, 'loss/train': 37.23066329956055}\n",
      "{'lr': [0.000242, 0.000242], 'samples/contexts': 124160, 'samples/tokens': 31784960, 'gradient_steps': 484, 'loss/train': 37.507835388183594}\n",
      "{'lr': [0.00024249999999999999, 0.00024249999999999999], 'samples/contexts': 124416, 'samples/tokens': 31850496, 'gradient_steps': 485, 'loss/train': 36.293312072753906}\n",
      "{'lr': [0.000243, 0.000243], 'samples/contexts': 124672, 'samples/tokens': 31916032, 'gradient_steps': 486, 'loss/train': 37.29035949707031}\n",
      "{'lr': [0.0002435, 0.0002435], 'samples/contexts': 124928, 'samples/tokens': 31981568, 'gradient_steps': 487, 'loss/train': 37.48421859741211}\n",
      "{'lr': [0.000244, 0.000244], 'samples/contexts': 125184, 'samples/tokens': 32047104, 'gradient_steps': 488, 'loss/train': 38.14043426513672}\n",
      "{'lr': [0.0002445, 0.0002445], 'samples/contexts': 125440, 'samples/tokens': 32112640, 'gradient_steps': 489, 'loss/train': 37.55328369140625}\n",
      "{'lr': [0.000245, 0.000245], 'samples/contexts': 125696, 'samples/tokens': 32178176, 'gradient_steps': 490, 'loss/train': 37.34675598144531}\n",
      "{'lr': [0.0002455, 0.0002455], 'samples/contexts': 125952, 'samples/tokens': 32243712, 'gradient_steps': 491, 'loss/train': 37.67660903930664}\n",
      "{'lr': [0.000246, 0.000246], 'samples/contexts': 126208, 'samples/tokens': 32309248, 'gradient_steps': 492, 'loss/train': 37.51447296142578}\n",
      "{'lr': [0.00024650000000000003, 0.00024650000000000003], 'samples/contexts': 126464, 'samples/tokens': 32374784, 'gradient_steps': 493, 'loss/train': 38.037628173828125}\n",
      "{'lr': [0.000247, 0.000247], 'samples/contexts': 126720, 'samples/tokens': 32440320, 'gradient_steps': 494, 'loss/train': 37.25826644897461}\n",
      "{'lr': [0.0002475, 0.0002475], 'samples/contexts': 126976, 'samples/tokens': 32505856, 'gradient_steps': 495, 'loss/train': 37.86787033081055}\n",
      "{'lr': [0.000248, 0.000248], 'samples/contexts': 127232, 'samples/tokens': 32571392, 'gradient_steps': 496, 'loss/train': 38.237213134765625}\n",
      "{'lr': [0.0002485, 0.0002485], 'samples/contexts': 127488, 'samples/tokens': 32636928, 'gradient_steps': 497, 'loss/train': 37.47132873535156}\n",
      "{'lr': [0.000249, 0.000249], 'samples/contexts': 127744, 'samples/tokens': 32702464, 'gradient_steps': 498, 'loss/train': 37.29462432861328}\n",
      "{'lr': [0.0002495, 0.0002495], 'samples/contexts': 128000, 'samples/tokens': 32768000, 'gradient_steps': 499, 'loss/train': 36.483253479003906}\n",
      "{'lr': [0.00025, 0.00025], 'samples/contexts': 128256, 'samples/tokens': 32833536, 'gradient_steps': 500, 'loss/train': 38.311073303222656}\n",
      "{'lr': [0.0002505, 0.0002505], 'samples/contexts': 128512, 'samples/tokens': 32899072, 'gradient_steps': 501, 'loss/train': 38.01966857910156}\n",
      "{'lr': [0.00025100000000000003, 0.00025100000000000003], 'samples/contexts': 128768, 'samples/tokens': 32964608, 'gradient_steps': 502, 'loss/train': 37.41782760620117}\n",
      "{'lr': [0.0002515, 0.0002515], 'samples/contexts': 129024, 'samples/tokens': 33030144, 'gradient_steps': 503, 'loss/train': 38.163612365722656}\n",
      "{'lr': [0.000252, 0.000252], 'samples/contexts': 129280, 'samples/tokens': 33095680, 'gradient_steps': 504, 'loss/train': 37.347557067871094}\n",
      "{'lr': [0.0002525, 0.0002525], 'samples/contexts': 129536, 'samples/tokens': 33161216, 'gradient_steps': 505, 'loss/train': 38.48773193359375}\n",
      "{'lr': [0.000253, 0.000253], 'samples/contexts': 129792, 'samples/tokens': 33226752, 'gradient_steps': 506, 'loss/train': 37.50177764892578}\n",
      "{'lr': [0.0002535, 0.0002535], 'samples/contexts': 130048, 'samples/tokens': 33292288, 'gradient_steps': 507, 'loss/train': 37.37704849243164}\n",
      "{'lr': [0.000254, 0.000254], 'samples/contexts': 130304, 'samples/tokens': 33357824, 'gradient_steps': 508, 'loss/train': 36.92290115356445}\n",
      "{'lr': [0.0002545, 0.0002545], 'samples/contexts': 130560, 'samples/tokens': 33423360, 'gradient_steps': 509, 'loss/train': 36.984561920166016}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebadcec42aa340fb898ef559cade8b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 5.631961345672607, 'perplexity': 279.209228515625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdbanman/tmp/env/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [0.000255, 0.000255], 'samples/contexts': 130816, 'samples/tokens': 33488896, 'gradient_steps': 510, 'loss/train': 36.41244125366211}\n",
      "{'lr': [0.00025550000000000003, 0.00025550000000000003], 'samples/contexts': 131072, 'samples/tokens': 33554432, 'gradient_steps': 511, 'loss/train': 36.874427795410156}\n",
      "{'lr': [0.000256, 0.000256], 'samples/contexts': 131328, 'samples/tokens': 33619968, 'gradient_steps': 512, 'loss/train': 36.71207046508789}\n",
      "{'lr': [0.0002565, 0.0002565], 'samples/contexts': 131584, 'samples/tokens': 33685504, 'gradient_steps': 513, 'loss/train': 38.00460433959961}\n",
      "{'lr': [0.000257, 0.000257], 'samples/contexts': 131840, 'samples/tokens': 33751040, 'gradient_steps': 514, 'loss/train': 37.89382553100586}\n",
      "{'lr': [0.0002575, 0.0002575], 'samples/contexts': 132096, 'samples/tokens': 33816576, 'gradient_steps': 515, 'loss/train': 37.34954833984375}\n",
      "{'lr': [0.00025800000000000004, 0.00025800000000000004], 'samples/contexts': 132352, 'samples/tokens': 33882112, 'gradient_steps': 516, 'loss/train': 37.12284851074219}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     20\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m     21\u001b[0m         {\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_scheduler\u001b[38;5;241m.\u001b[39mget_lr(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         }\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps\n\u001b[0;32m---> 30\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch_step \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/tmp/env/lib/python3.10/site-packages/accelerate/accelerator.py:1745\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1745\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tmp/env/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tmp/env/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dro_alpha = 0.8\n",
    "\n",
    "epoch_step_logging_interval = 8\n",
    "\n",
    "gradient_accumulation_steps = 8\n",
    "gradient_step_eval_interval = 30\n",
    "gradient_steps_since_eval = 0\n",
    "gradient_steps = 0\n",
    "\n",
    "num_eval_batches = 50\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    for epoch_step, batch in tqdm(\n",
    "        enumerate(train_dataloader, start=1), total=len(train_dataloader)\n",
    "    ):\n",
    "        logits = model(batch[\"input_ids\"]).logits\n",
    "        loss = dro_loss(batch[\"input_ids\"], logits, alpha=dro_alpha)\n",
    "        if epoch_step % epoch_step_logging_interval == 0:\n",
    "            accelerator.print(\n",
    "                {\n",
    "                    \"lr\": lr_scheduler.get_lr(),\n",
    "                    \"samples/contexts\": epoch * epoch_step * batch_size,\n",
    "                    \"samples/tokens\": epoch * epoch_step * batch_size * context_length,\n",
    "                    \"gradient_steps\": gradient_steps,\n",
    "                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
    "                }\n",
    "            )\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if epoch_step % gradient_accumulation_steps == 0:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            gradient_steps += 1\n",
    "            gradient_steps_since_eval += 1\n",
    "            \n",
    "        if gradient_steps_since_eval >= gradient_step_eval_interval:\n",
    "            gradient_steps_since_eval = 0\n",
    "            eval_loss, perplexity = evaluate(num_eval_batches)\n",
    "            accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
    "            model.train()\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(output_dir)\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Training in progress epoch step {epoch * epoch_step}\", blocking=False\n",
    "                )\n",
    "\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a13a52002b4d368057093084ce72d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2140e102814c6794f5a704d7daba8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99cfb62d021645de8d38ab54ec79baf8",
      "placeholder": "​",
      "style": "IPY_MODEL_c5bc3cab55694118950d3dc4d9e6e6ee",
      "value": "Downloading data files:   0%"
     }
    },
    "0fe84c02c7ed45e8b884a5125800a033": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "255c8fd4d1e54761bfa729a7b443a3ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25b3444ab68645b79966431d48a3faf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_79c991843c254478bdfc163b78ac4969",
      "placeholder": "​",
      "style": "IPY_MODEL_95b39ca67a604851ae10e6c576868c06",
      "value": ""
     }
    },
    "261187df1bfc424b95d7a2c7b5e92501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a721264a5d74d16aedc22da8583212f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30b524588ed94919a864932febf1e79a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "387f1ccf1b5748a0ae769665e5fbb01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "3a1793e578684ad49222234673ff73b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41017c952c5d4294a94913016c452f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42d56dfa125644998fb1e4ca81a2b287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43a39ad612db48c996743f6cbb673c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_c2d532801b8e4685a3ab792fb1a6185b",
      "style": "IPY_MODEL_255c8fd4d1e54761bfa729a7b443a3ab",
      "value": true
     }
    },
    "4f8d3a91d90d41e3a709b9d9a76a3ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a735719819dd42738b442972453fe1f4",
      "placeholder": "​",
      "style": "IPY_MODEL_7a94bb262c214cbdabb70e807d9bec5e",
      "value": "Downloading data:  27%"
     }
    },
    "4fa97e9f2ea142c096e9cbef7e8ff806": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d2140e102814c6794f5a704d7daba8c",
       "IPY_MODEL_cacb0efb34d7461a921114c087731b00",
       "IPY_MODEL_ab6d16f322f342b798a76c10947fe6ff"
      ],
      "layout": "IPY_MODEL_41017c952c5d4294a94913016c452f39"
     }
    },
    "511d6aa0a8b643c0bac7924cf064b726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5db4d2001e9c4d4b822de1e841388255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "60912ca8eac54f6b828f30e6c594f475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec851e04726b40b9aa70b0a10352e2f7",
      "placeholder": "​",
      "style": "IPY_MODEL_a22df49373804d60bb3e0f65157e55f4",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "6f9e559d4bd14a51ab63ad2821e12d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4e597a4763847e29cb1cc9b59f15ee9",
       "IPY_MODEL_25b3444ab68645b79966431d48a3faf3",
       "IPY_MODEL_43a39ad612db48c996743f6cbb673c7b",
       "IPY_MODEL_f1211ac8e2854fefa80c4392704bd955",
       "IPY_MODEL_60912ca8eac54f6b828f30e6c594f475"
      ],
      "layout": "IPY_MODEL_387f1ccf1b5748a0ae769665e5fbb01f"
     }
    },
    "79c991843c254478bdfc163b78ac4969": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a94bb262c214cbdabb70e807d9bec5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c6a487331d54fd582368349672ccb18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b36b3cf1b7247238bc7e3079da51096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5903175fc5b47a1a0ab02d653d4a0a5",
      "placeholder": "​",
      "style": "IPY_MODEL_bcd26642b2fb46fa96a64f72440160ac",
      "value": " 2.21G/8.25G [00:42&lt;01:01, 98.0MB/s]"
     }
    },
    "934bc2a89848404ab9cd8d2aef464fb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04a13a52002b4d368057093084ce72d0",
      "max": 8252554086,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_261187df1bfc424b95d7a2c7b5e92501",
      "value": 2211401728
     }
    },
    "95b39ca67a604851ae10e6c576868c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99cfb62d021645de8d38ab54ec79baf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a22df49373804d60bb3e0f65157e55f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a735719819dd42738b442972453fe1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab6d16f322f342b798a76c10947fe6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c6a487331d54fd582368349672ccb18",
      "placeholder": "​",
      "style": "IPY_MODEL_42d56dfa125644998fb1e4ca81a2b287",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "b5903175fc5b47a1a0ab02d653d4a0a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcd26642b2fb46fa96a64f72440160ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2d532801b8e4685a3ab792fb1a6185b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4e597a4763847e29cb1cc9b59f15ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a721264a5d74d16aedc22da8583212f",
      "placeholder": "​",
      "style": "IPY_MODEL_511d6aa0a8b643c0bac7924cf064b726",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "c5bc3cab55694118950d3dc4d9e6e6ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cacb0efb34d7461a921114c087731b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a1793e578684ad49222234673ff73b2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef08c5ba6881497b840b1d08331d32cf",
      "value": 0
     }
    },
    "ec851e04726b40b9aa70b0a10352e2f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef08c5ba6881497b840b1d08331d32cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1211ac8e2854fefa80c4392704bd955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_30b524588ed94919a864932febf1e79a",
      "style": "IPY_MODEL_5db4d2001e9c4d4b822de1e841388255",
      "tooltip": ""
     }
    },
    "fd4e6835dc77454c8e946d7c1902e001": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f8d3a91d90d41e3a709b9d9a76a3ff7",
       "IPY_MODEL_934bc2a89848404ab9cd8d2aef464fb4",
       "IPY_MODEL_8b36b3cf1b7247238bc7e3079da51096"
      ],
      "layout": "IPY_MODEL_0fe84c02c7ed45e8b884a5125800a033"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
